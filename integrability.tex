\documentclass[main.tex]{subfiles}
\begin{document}

\chapter{Classical $R$-matrix and Lax representation}
This chapter is based on \cite[Section 3]{oevel1989r}.

\section[Classical R-matrix]{Classical $R$-matrix}
\begin{definition}
	An \textbf{$R$-matrix} is a linear map $R: \lalg \to \lalg$ on a Lie algebra $\lalg$ having the property that the modified bracket
	\begin{eqalign}
		[X,Y]_R = [RX,Y]+[X,RY], \quad \forall X,Y \in \lalg
	\end{eqalign}
	defines a Lie product on $\lalg$. Equivalently, $(\lalg, [\bullet, \bullet]_R)$ should be a Lie algebra (in particular $[\bullet, \bullet]_R$ satisfy the Jacobi identity).
	To the $R$-bracket on $\lalg$ is associated a Poisson bracket on $\lalg^*$:
	\begin{eqalign}
		\{f,g\}_R\vert_\xi = \langle [df\vert_\xi, dg\vert_\xi]_R, \xi \rangle, \quad \forall \xi \in \lalg^*,\, \forall f,g \in \Cinfty(\lalg^*).
	\end{eqalign}
\end{definition}

\begin{proposition}
	A linear map $R: \lalg \to \lalg$ on a Lie algebra $(\lalg, [\bullet,\bullet])$ is an $R$-matrix if and only if
	\begin{eqalign}
	\label{eq:cond_R_matrix_B}
		[B_R(X,Y), Z] + [B_R(Y,Z), X] + [B_R(Z,X), Y] = 0
	\end{eqalign}
	where
	\begin{eqalign}
		B_R(X,Y) = [RX, RY]- R[X,Y]_R
	\end{eqalign}
\end{proposition}
\begin{proof}
	Exercise, it's just a computation.
\end{proof}

The operator $B_R$ measures how far $R$ is from being a Lie algebra homomorphism. It is quadratic on both terms. Notice that, while $B_R = 0$ certainly satisfies the hypotheses of the theorem, it doesn't have to be the case:

\begin{corollary}
	A \emph{sufficient} condition for a linear map $R: \lalg \to \lalg$ to be an $R$-matrix is for $R$ to satisfy the \textbf{modified Yang--Baxter equation} (mYBE):
	\begin{eqalign}
	\label{eq:mYBE}
		B_R(X,Y) = -c[X,Y],
	\end{eqalign}
	for some $c \in \R$.
\end{corollary}
\begin{proof}
	If Equation~\eqref{eq:mYBE} is satisfied, then Equation~\eqref{eq:cond_R_matrix_B} follows immediately using Jacobi identity.
\end{proof}

Clearly, up to rescaling of $R$, there are actually just two cases of the mYBE: the one with $c=0$ (corresponding to the case where $R$ is an automorphism of the algebra) and the one with $c=1$. For this second case, there is a special class of solutions that arises in a very simple manner:

\begin{construction}
	Let $(\lalg, [\bullet,\bullet])$ be a Lie algebra which decomposes (as vector space!) as $\lalg = \lalg_+ \dir \lalg_-$, for $\lalg_\pm \leq \lalg$. We do \textbf{not} require $[\lalg_+, \lalg_+] = 0$, i.e. the direct sum does not need to be one of Lie algebras. Let $\pr_\pm$ denote the projections onto $\lalg_+$ and $\lalg_+$ respectively and write $X_\pm = \pr_\pm X$ for any vector $X \in \lalg$. Then we claim $R = \frac12 (\pr_+ - \pr_-)$ is an $R$-matrix. In fact observe that, by virtue of the bilinearity of $[\bullet,\bullet]$, the $R$-bracket follows the splitting perfectly:
	\begin{eqalign}
		[X,Y]_R &= \frac12 [X_+ - X_-, Y] + \frac12 [X, Y_+ - Y_-]\\
			&= \frac12 \left( [X_+ - X_-, Y_+ + Y_-] + [X_+ + X_-, Y_+ - Y_-] \right)\\
			&= \frac12 \left( [X_+, Y_+] - [X_-, Y_-]\right)
	\end{eqalign}
	Then its clear we can decompose the Jacobi identity of $[\bullet,\bullet]_R$ into two Jacobi identities for $[\bullet,\bullet]$, which hold by assumption. This class of examples is very ample as any decomposition of $\lalg$ works.
\end{construction}

Occasionally people find solutions of the mYBE which do not come from the decomposition we've treated. In fact, there are a lot of examples but the great majority of them is in the infinite-dimensional context. Indeed, this theory comes from that environment (in particular the study of PDEs), and only later it was realized there was some honest finite-dimensional geometry behind it.

\begin{proposition}
\label{prop:cas_ham_field}
	If $h \in \Cas(\lalg^*, \{\bullet,\bullet\})$ then its Hamiltonian vector field with respect to the Poisson $R$-bracket is
	\begin{eqalign}
		X^R_h\vert_\alpha = \ad^*_{R(dh\vert_\alpha)}\vert_\alpha.
	\end{eqalign}
\end{proposition}
\begin{proof}
	For all $f \in \Cinfty(\lalg^*)$ and $\alpha \in \lalg^*$,
	\begin{eqalign}
	\label{eq:ham_vec_field_R_matr_comp}
		X^R_h(f)\vert_\alpha &= \{f,h\}_R\vert_\alpha\\
			&= \langle [df\vert_\alpha, dh\vert_\alpha]_R, \alpha \rangle\\
			&= \langle [R(df\vert_\alpha), dh\vert_\alpha] + [df\vert_\alpha, R(dh\vert_\alpha)], \alpha \rangle\\
			&= \langle [R(df\vert_\alpha), dh\vert_\alpha], \alpha \rangle + \langle [df\vert_\alpha, R(dh\vert_\alpha)], \alpha \rangle\\
			&= \langle \ad_{R(df\vert_\alpha)}\vert_{dh\vert_\alpha}, \alpha \rangle - \langle \ad_{R(dh\vert_\alpha)}\vert_{df\vert_\alpha}, \alpha \rangle\\
			&= -\ad^*_{R(df\vert_\alpha)}(h)\vert_\alpha + \ad^*_{R(dh\vert_\alpha)}(f)\vert_\alpha
	\end{eqalign}
	Since $\ad^*_X$ is tangent to the symplectic leaves (Theorem~\ref{th:coadj_is_tangent}) and $h$ is Casimir, the first term vanishes and the claim follows.
\end{proof}

\begin{corollary}
\label{cor:cas_are_inherited}
	If $f,g, \in \Cas(\lalg^*, \{\bullet,\bullet\})$, then they commute with respect to the Poisson $R$-bracket.
\end{corollary}
\begin{proof}
	Since $f$ is constant on coadjoint orbits:
	\begin{eqalign}
		\{f,g\}_R = \ad^*_{R(dg)}(f) = 0.
	\end{eqalign}
\end{proof}

\begin{remark}
	The flow of $X^R_h$ for $h$ Casimir lies in the intersection of the coadjoint orbits of $(\lalg, [\bullet,\bullet])$ and $(\lalg, [\bullet,\bullet]_R)$. So it is $\ad^*$ of something but also the $\ad^*_R$ of something.
\end{remark}

\subsection{$R$-matrix and $\Ad$-invariant forms}

Let $(\bullet,\bullet)$ be an $\Ad$-invariant (bilinear, non-degenerate) form on $\lalg$. Then this provides an identification
\begin{eqalign}
	\lalg^* &\isolongto \lalg\\
	\alpha &\longleftrightarrow L
\end{eqalign}
This isomorphism also induces the following identifications:
\begin{eqalign}
\label{eq:identif_lalg_colalg_R}
	h(\alpha) \in \Cinfty(\lalg^*) &\longleftrightarrow f(L) \in \Cinfty(\lalg)\\
	dh \vert_\alpha &\longleftrightarrow \nabla f \vert_L\\
	\ad_X^* \vert_\alpha &\longleftrightarrow -\ad_X \vert_L\\
	(R^* : \lalg^* \to \lalg^*) &\longleftrightarrow (R^\dagger: \lalg \iso \lalg^* \overset{R^*}\to \lalg^* \iso \lalg )
\end{eqalign}
where $R^*$ denotes the transposed operator
\begin{eqalign}
	R^* : \lalg^* &\longto \lalg^*\\
	\alpha &\longmapsto R^*\alpha	\comment{s.t.} \quad \langle R^*\alpha, X \rangle = \langle \alpha, RX \rangle \quad \forall X \in \lalg
\end{eqalign}
and $R^\dagger$ is the operator induced on $\lalg$ by $R^*$.

\begin{proposition}
	Using previous identifications, given $h\in\Cinfty(\lalg^*)$, we have the following identification for the Hamiltonian vector field with respect to the Poisson $R$-bracket:
	\begin{eqalign}
		X_h^R \vert_\alpha \longleftrightarrow \der{L}{t}\vert_L &= -\ad_{R\nabla f\vert_L} \vert_L - R^\dagger \ad_{\nabla f\vert_L} \vert_L\\
		&= [L, R\nabla f\vert_L] + R^\dagger [L, \nabla f\vert_L]
	\end{eqalign}
\end{proposition}
\begin{proof}
	Using computation in Equation~\eqref{eq:ham_vec_field_R_matr_comp} we get for all $Y \in \lalg$:
	\begin{eqalign}
		\langle X^R_h\vert_\alpha, Y \rangle &= \langle \alpha, [Y, dh\vert_\alpha]_R \rangle\\
			&= \langle \alpha, [RY, dh \vert_\alpha] \rangle + \langle \alpha, R dh\vert_\alpha ] \rangle\\
			&= \langle \alpha, -\ad_{dh\vert_\alpha}\vert_{RY} \rangle + \langle \alpha, -\ad_{R dh \vert_\alpha} \vert_Y \rangle\\
			&= \langle \ad^*_{dh\vert_\alpha} \vert_\alpha, RY \rangle + \langle \ad^*_{R dh \vert_\alpha} \vert_\alpha, Y \rangle\\
			&= \langle R^* (\ad^*_{dh \vert_\alpha} \vert_\alpha) + \ad^*_{R dh \vert_\alpha} \vert_\alpha, Y \rangle
	\end{eqalign}
	which implies, using identifications of Equation~\eqref{eq:identif_lalg_colalg_R}:
	\begin{eqalign}
		X^R_h\vert_\alpha = R^* (\ad^*_{dh \vert_\alpha} \vert_\alpha) + \ad^*_{R dh \vert_\alpha} \vert_\alpha \longleftrightarrow -R^\dagger \ad_{\nabla f\vert_L} \vert_L - \ad_{R\nabla f\vert_L} \vert_L
	\end{eqalign}
\end{proof}

\begin{corollary}
	Using previous notation, if $h \in  \Cas(\lalg^*, \{\bullet,\bullet\})$, then
	\begin{eqalign}
		 \der{L}{t}\vert_L &= -\ad_{R\nabla f\vert_L} \vert_L = [L, R\nabla f\vert_L]
	\end{eqalign}
\end{corollary}
\begin{proof}
	Follows directly from the result of the previous proposition mimicking the last piece of the proof of Proposition~\ref{prop:cas_ham_field}.
\end{proof}

\begin{example}
	In the case $\lalg = \mathfrak{gl}(n)$ (the Lie algebra associated to square matrices with complex entries, but seen as a real manifold). Then $\Ad_g X = gXg^{-1}$. We consider the form $(X,Y) := \trace(XY)$. It is $\Ad$-invariant since
	\begin{eqalign}
		\trace (gXg^{-1}gYg^{-1}) &= \trace (gXY g^{-1})\\
			&= \trace (g^{-1}gXY) \comment{b.c. trace is cyclic-invariant}\\
			&= \trace XY.
	\end{eqalign}
	Some Casimir functions in $(\lalg^*, \{\bullet,\bullet\})$ are given by $h_i = \trace (X^i)$ (where the apex is an exponent), because any such function is $\Ad$-invariant, hence constant on (co)adjoint orbits.\footnote{Indeed 
	\begin{eqalign}
		((\Ad_g)^* h_i)(X) = h_i (g X g^{-1}) = \trace(g X g^{-1}g X g^{-1}\dots g X g^{-1}) = \trace(g X^i g^{-1}) = \trace(X^i) = h_i(X)
	\end{eqalign}}

	By the last corollary, \emph{any} Casimir function $h$ on the Poisson algebra on $\lalg^*$ let's you find the evolution of any $X \in \lalg$:
	\begin{eqalign}
	\label{eq:evo_lalg_R_matrix}
		\der{X}{t} =[X, R\nabla h \vert_X]
	\end{eqalign}
	The $h_i$, for $i=1,\ldots,n$, are in involution, so they represent symmetries of the system, and hopefully can be used to obtain a foliation of the manifold into orbits. These will turn out to be the most general spectral invariants of the matrix $X$.
\end{example}

These last ideas will be applied in the informative example of the Toda lattice (Example~\ref{ex:toda_lattice}).

\begin{remark}
	The study of the geometry and topology of coadjoint orbits in relation to the spectral theory of the chosen Lie groups / algebra is necessary to ascertain the complete integrability of such Hamiltonian systems.
\end{remark}

\section{Lax Representations}
\begin{definition}
	Given a vector field $X \in \fields(N)$ on a smooth manifold $N$, an open $U \subseteq N$, a \textbf{Lax representation of $(X, U)$} is the collection $(L,M)$ of a smooth immersion $L : U \into \gl(n)$ and a smooth map $M : U \to \gl(n)$ such that
	\begin{eqalign}
		L_*X\vert_{L(x)} = [L(x), M(x)]
	\end{eqalign}
	or, equivalently,
	\begin{eqalign}
		\der{L}{t} = [L,M].
	\end{eqalign}
	where $\der{L}{t}$ is seen as a vector field on $\im L$.
\end{definition}

It mimics the evolution of a quantum operator in the Heisenberg formalism. The second equation in the definition should be meant as a generalization of Equation~\eqref{eq:evo_lalg_R_matrix} to a more general situation where no Poisson structure has been defined.

\begin{proposition}
	The eigenvalues $\lambda_1(x), \ldots, \lambda_n(x)$ of the Lax matrix $L(x)$ are integrals of motion of the system $\der{L}{t} = [L,M]$, i.e.
	\begin{eqalign}
		\der{\lambda_i(x(t))}{t}=0.
	\end{eqalign}
\end{proposition}
\begin{proof}
	Let $t_k = \trace (L^k)$, then eigenvalues of $L$ are roots of its characteristic polynomial:
	\begin{eqalign}
		\det(L- \lambda I) = (-1)^n(\lambda^n + c_1 \lambda^{n-1} + \ldots + c_n).
	\end{eqalign}
	Its coefficients can be written in terms of the trace through \textbf{Newton's formula}:
	\begin{eqalign}
		c_m = - \frac{t_m}m + \frac1{2!} \sum_{i+j = m} \frac{t_it_j}{ij} - \frac1{3!} \sum_{i+j +k = m} \frac{t_it_jt_k}{ijk} + \ldots + (-1)^m \frac{t_1^m}{m!}.
	\end{eqalign}
	Now, using the cyclic invariance of the trace to tackle the derivative, we obtain:
	\begin{eqalign}
		\der{}{t} \trace L^k &= k \trace\Big(\der{L}{t} L^{k-1}\Big)\\ 
			&= k\trace ([L,M] L^{k-1})\\
			&= k \trace (LML^{k-1} - ML^k)\\
			&= 0.
	\end{eqalign}
	Then, as $c_1, \ldots, c_n$ depend only on the traces, which we've just shown to be constant of motions, the eigenvalues are constant of motions as well.
\end{proof}

\begin{theorem}
	Let $(L, M)$ be a Lax representation for a vector field on some smooth manifold $N$. Let $G: N \to \GL(n)$ be a smooth map. Then
	\begin{eqalign}
		L' = GLG^{-1},\quad M'=GMG^{-1}- \der{G}{t}G^{-1},
	\end{eqalign}
	where $t$ is the time of the Lax equation, is another Lax representation for the vector field.
\end{theorem}
\begin{remark}
	The transformation is in the same spirit of the gauge transformation of a fiber bundle connection!
\end{remark}
\begin{proof}
	Using the formula $\der{G^{-1}}t = -G^{-1} \der{G}t G^{-1}$, we get
	\begin{eqalign}
		\der{L'}{t} &= \der{}{t}(GLG^{-1})\\[1ex]
			&= \der{G}{t}LG^{-1} +G[L,M]G^{-1} - GLG^{-1}\der{G}{t}G^{-1}\\[1ex]
			&= \der{G}t \textcolor{blue}{G^{-1}G}LG^{-1} + [GLG^{-1}, GMG^{-1}] - GLG^{-1}\der{G}{t}G^{-1}\\[1ex]
			&= \left[\der{G}tG^{-1}, L' \right] + [L', GMG^{-1}]\\[1ex]
			&= [L', M'].
	\end{eqalign}
\end{proof}
\begin{corollary}
	Since $L'$ is conjugate to $L$, hence they have the same eigenvalues, the Lax representation obtained in this way yields the same integrals of motion.
\end{corollary}

\begin{example}[{Classical finite Toda lattice, from \cite{oevel1989r}}]
\label{ex:toda_lattice}
	Take $\lalg = \gl(n)$ as before and split it into $\lalg_+ \dir \lalg_-$, where $\lalg_+$ is the space of lower triangular matrices and $\lalg_- = \so(n)$ the space of skew-symmetric ones. We will use the duality given by the trace to identify $\lalg$ with $\lalg^*$. Then
	\begin{eqalign}
		\lalg_+^* \iso \lalg_-^\perp = \{\text{symmetric matrices}\},
	\end{eqalign}
	and
	\begin{eqalign}
		\lalg_-^* \iso \lalg_+^\perp = \{\text{strictly lower triangular matrices}\}.
	\end{eqalign}
	in such a way that we decomposed $\lalg^*$ too: $\lalg^* = \lalg_+^* \dir \lalg_-^*$.
	Consider the projections
	\begin{eqalign}
		\pr_+(L) &= \underline\ell(L) + \overline{u}(L)^T + d(L),\\
		\pr_-(L) &= \overline{u}(L) - \overline{u}(L)^T,
	\end{eqalign}
	where $\underline{\ell}$ extracts the strictly lower triangular part, $\overline{u}$ the strictly upper triangular part and $d$ the diagonal. Likewise, we define projection operators on the dual algebra:
	\begin{eqalign}
		\pr_+^*(L) &= d(L) + \overline{u}(L) + \overline{u}(L)^T,\\
		\pr_-^*(L) &= \underline\ell(L)-\overline{u}(L)^T.
	\end{eqalign}
	Then let
	\begin{eqalign}
		R(L) &= \pr_+(L) - \pr_-(L) = \underline\ell(L) + 2 \overline{u}(L)^T + d(L) - \overline u(L)\\
		R^*(L) &= \pr_+^*(L)-\pr_-^*(L) = -\underline\ell(L) + 2\overline u(L)^T + d(L) + \overline u(L).
	\end{eqalign}
	We will build a hierarchy of commuting Hamiltonian equations on the space $\lalg$.
	Now we can put a Poisson structure on $\lalg$:
	\begin{eqalign}
		\Pi^\sharp_R(A)\vert_L = [L,RA] + R^*[L,A].
	\end{eqalign}
	We could now get the integrals of motion from the traces, but that approach would be uninformative for the purpose of finding the system corresponding to the Toda lattice. We take another route. Let
	\begin{eqalign}
		S = \{ b+aT_- + T_-a\} \incat{LieAlg}\subseteq \lalg
	\end{eqalign}
	where
	\begin{eqalign}
		a = \begin{pmatrix}
			a_1 & & & &\\
			& a_2 & & &\\
			& & \ddots & &\\
			& & & a_{n-1} &\\
			& & & & 0
		\end{pmatrix},& \quad b = \begin{pmatrix}
			b_1 & & & &\\
			& b_2 & & &\\
			& & \ddots & &\\
			& & & b_{n-1} &\\
			& & & & b_n
		\end{pmatrix}\\[2ex]
		T_+ = \begin{pmatrix}
			0 & 1 & & &\\
			& 0 & 1 & &\\
			& & \ddots & &\\
			& & & 0 & 1\\
			& & & & 0
		\end{pmatrix},& \quad
		T_-  = \begin{pmatrix}
			0 & & & &\\
			1& 0 & & &\\
			& & \ddots & &\\
			& & 1& 0 &\\
			& & & 1& 0
		\end{pmatrix}.
	\end{eqalign}
	One could prove that, for any $L \in S$ and $A \in \lalg$, $\Pi^\sharp_R(A)\vert_L \in S$, which means $\Pi^\sharp_R(A)$ is tangent to $S$ if $L \in S$. This means $\im(\Pi_R(L)) \subseteq TS$, hence by Theorem~\ref{eq:poisson_submanifold_condition} there is a unique Poisson submanifold structure on $S$, given by the restriction of $\Pi_R$ to $S$. The functions $c_k = \frac1k \trace L^k$ are Casimir for $(\lalg^*, \{\bullet, \bullet\}_R)$, and restricting them to $S$ we get
	\begin{eqalign}
		\der{L}{t_k} = [L, R\nabla c_k] = [L, RL^{k-1}] = -2[L, P_-(L^{k-1})]
	\end{eqalign}
	and $\{c_i, c_j\}_R=0$. For instance, take $k=2$.
	\begin{eqalign}
		\der{L}{t_2} = [L, R\nabla c_2] = [L, RL] \iff \begin{dcases}
			\dot{b}_i = 4(a_i^2 - a_{i-1}^2)\\
			\dot{a}_i = 2a_i(b_{i+1} - b_i)
		\end{dcases}
	\end{eqalign}
	or equivalently
	\begin{eqalign}
		\begin{dcases}
			\dot v_i = \e^{u_i+1}-\e^{u_i}\\
			\dot u_i = v_i-v_{i-1}
		\end{dcases}
		\quad \text{where} \quad
		\begin{dcases}
			a_i \mapsto \e^{\frac{u_i+1}2}\\
			b_i \mapsto v_i\\
			t \mapsto \frac t4
		\end{dcases}
	\end{eqalign}
	These are \textbf{Toda equations} and describe a finite line of particles interacting (exponentially) with their neighbours. This is a good example of a system which is not integrable at first sight, but where its abstract study brings out the $n$ integral of motions given by the Casimir functions we found, so we can completely integrate it.
\end{example}

\chapter{Bihamiltonian structures}
\section{Bihamiltonian structures}
We can think of the space of Poisson structures as a manifold, the submanifold of the manifold of bivectors defined by the quadratic equation \eqref{eq:jacobi_id_for_pi_tensor}. It is not a vector space \emph{per se}, but since it lives inside $\Lambda^2(M)$, which \emph{is} a vector space, can contain subspaces.

\begin{definition}
	A \textbf{bihamiltonian structure} on a smooth manifold $M$ is a $2$-dimensional linear subspace of the space of Poisson structures on $M$.
\end{definition}

An ordered basis $(\Pi_0, \Pi_1)$ of such a space is called a \textbf{pair of compatible Poisson tensors}. Since this means any linear combination of them is again a Poisson tensor, we've already seen we must have
\begin{eqalign}
	[a_0\Pi_0 + a_1\Pi_1,a_0\Pi_0 + a_1\Pi_1] = 0 \quad\Longrightarrow\quad [\Pi_0, \Pi_1] = 0.
\end{eqalign}

Let us denote $\{\bullet,\bullet\}_i$ the Poisson bracket associated to the Poisson tensor $\Pi_i$.

\begin{theorem}[Magri, {\cite[Lemma 1.2.4]{dubrovin2005}}]
\label{th:magri}
	Let $M$ be a smooth manifold equipped with two different Poisson structures, $\Pi_0$ and $\Pi_1$. Consider a sequence of functions $\seq{h}{n} \subseteq \Cinfty(M)$ satisfying the following ``bihamiltonian recursion'':\footnote{Equivalently: $\Pi_1^\sharp (dh_{p+1}) = \Pi_2^\sharp(dh_p))$.}
	\begin{eqalign}
		\{\bullet,h_{p+1}\}_0 = \{\bullet,h_p\}_1, \quad \forall p \in \N.
	\end{eqalign}
	Then $\{h_p,h_q\}_0 = \{h_p,h_q\}_1 = 0$ for all $p,q \in \N$.
\end{theorem}
\begin{remark}
	The relation is not really a recursion, since to really write $h_{p+1}$ in terms of $h_p$ one has to invert $\Pi_0^\sharp$ and then ``integrate'' which are both operations not possible in general (as $\Pi_0$ might be singular).
\end{remark}
\begin{remark}
	Let $n$ be the number of independent functions in the sequence $\seq{h}{n}$, since these function are in involution, their associated flows mutually commute in both the Poisson structures, hence we obtained a set of $n$ symmetries of our system that can be used to foliate it.
\end{remark}
\begin{proof}
	Suppose $q-p=2m$, for $m \neq 0$. Then, by using recursion and skew-symmetry:
	\begin{eqalign}
		\{h_p, h_q\}_0 &= \{h_p, h_{q-1}\}_1\\
		&= -\{h_{q-1}, h_p\}_1\\
		&= -\{h_{q-1}, h_{p+1}\}_0\\
		&= \{h_{p+1}, h_{q-1}\}_0
	\end{eqalign}
	We managed to dimish the difference of the indices of $2$, so that by repeating this $m$ times we'd arrive to $\{h_{p+m}, h_{q-m}\}_0 =0$. Likewise, if $q-p = 2m+1$ then we can arrive at
	\begin{eqalign}
		\{h_p, h_q\}_0 = \ldots = \{h_{p+m}, h_{q-m}\}_0 = \{h_{p+m}, h_{q-m-1}\}_1 = 0.
	\end{eqalign}
	Hence all the functions are in involution for the $0$-brackets, and by the recursion relation, it is a trivial exercise to check they are in involution for the $1$-bracket too.
\end{proof}

Notice \textbf{we actually didn't use the compatibility of $\Pi_0$ and $\Pi_1$ to get this result}. Indeed, it is not necessary. However a bihamiltonian structure gives us a canonical way to produce a sequence of functions in recursion in two particular cases:

\begin{enumerate}
	\item when the rank of any $a_0\Pi_0 + a_1\Pi_1 \in \Span_\R \{\Pi_0, \Pi_1\}$ is constant (and non-maximal) in some open subset\footnote{In this case we can always assume that the open subset of $\R^2$ contains the point $(1, 0)$ (this is always true up to linear transformations of $\Pi_0$ and $\Pi_1$), in such a way that the Poisson pencil defined in the following lives in such open subset.} of $\langle a_0, a_1\rangle \iso \R^2$, or
	\item when one of the Poisson structures is non-degenerate, hence we have at our disposal a symplectic structure (if this is the case the bihamiltonian recursion is truly a recursion).
\end{enumerate}

Let's start with the first one.

\section{The Hamiltonian recursion in the constant rank case}
\begin{definition}
	A marked line $\Pi_0 + \varepsilon \Pi_1$ in a bihamiltonian structure $\{\Pi_0, \Pi_1\}$ is called a \textbf{Poisson pencil}.
\end{definition}

\begin{lemma}[{\cite[Lemma 1.2.7]{dubrovin2005}}]
\label{lemma:comp_poisson_of_const_rank_same_cas}
	Let $\Pi_\varepsilon = \Pi_0 + \varepsilon \Pi_1$ be a Poisson pencil of constant and non-maximal rank in a neighbourhood of $\varepsilon=0$ and let $k = \cork(\Pi_0 + \varepsilon\Pi_1) = \cork(\Pi_0)$. If $c_1, c_2 \in \Cas(M, \Pi_0)$, then $\{c_1,c_2\}_1 = 0$.
\end{lemma}
\begin{remark}
	This is remindful of the alike theorem for Lax representations (Corollary~\ref{cor:cas_are_inherited}).
\end{remark}
\begin{proof}
	Let $2m = \rk(\Pi_0)$, so that $2m+k=\dim M$. Let us choose Darboux--Weinstein coordinates for $\Pi_0$ centered at $p \in M$ ($c^{ij}(p) = 0$ in the notation of Theorem~\ref{th:darboux_weinstein}). Then
	\begin{eqalign}
		\Pi_0^{ab}\vert_p = \begin{pmatrix}
			0 & I & 0\\
			-I & 0 & 0\\
			0 & 0 & 0
		\end{pmatrix}.
	\end{eqalign}
	Hence
	\begin{eqalign}
		(\Pi_0 + \varepsilon \Pi_1)^{ab}\vert_p = \begin{pmatrix}
			O(\varepsilon) & I + O(\varepsilon) & O(\varepsilon)\\
			-I + O(\varepsilon) & O(\varepsilon) & O(\varepsilon)\\
			O(\varepsilon)& O(\varepsilon) & O(\varepsilon)
		\end{pmatrix}.
	\end{eqalign}
	The fact that $\rk(\Pi_\varepsilon) = \rk(\Pi_0) = 2m$ implies the determinant of any minor of order $2m+1$ vanishes. In particular, consider the minor $M_{ij}$ we get from adjoining the $i$-th row and the $j$-th column ($2m < i,j \leq 2m+k$) to the upper left minor of size $2m$. Developing the determinant of such a minor with respect to the adjoined row, we obtain\footnotemark
	\begin{eqalign}
		0 = \det M_{ij}(\varepsilon)\vert_p = \underbrace{(-1)^{4m+2} (\Pi_0^{ij}\vert_p+ \varepsilon \Pi_1^{ij}\vert_p)}_{\text{rightmost element}} + \underbrace{O(\varepsilon^2)}_{\text{others}} = \varepsilon \Pi_1^{ij}\vert_p + O(\varepsilon^2), \quad \forall i,j.
	\end{eqalign}
	Since $\det M_{ij}\vert_p$ is a polynomial in $\varepsilon$ which vanishes on a whole neighbourood of $\varepsilon = 0$, thus it must be the zero polynomial, implying $\Pi_1^{ij}\vert_p = 0$ for $2m < i,j \leq 2m+k$. Since this holds for any $p \in M$ we just obtained $\Pi_1^{ij}=0$ in a neighbourhood of $\varepsilon=0$ for $2m < i,j \leq 2m+k$. Now recall that $\Pi^{ij} = \{x^i, x^j\}$, so this result about the components of $\Pi_1$ translates to the thesis, since the last $k$ coordinates of a Darboux--Weinstein system are (a basis for) Casimirs.
	\footnotetext{An appreciable digression should be made about how did we obtain the stated equalities. Eventually, the employed results are the consequence of a careful and attentive application of the definition of determinant to the peculiar structure the involved matrices have, hence a challenging, if pedant, exercise. Explicitly, we are using the fact that:
	\begin{eqalign}
		\left| \begin{matrix}
			O(\varepsilon) & I + O(\varepsilon)\\
			-I + O(\varepsilon) & O(\varepsilon)
		\end{matrix} \right| = 1 + O(\varepsilon),
	\end{eqalign}
	while the same matrix with any line replaced by one whose entries are $O(\varepsilon)$ has determinant $O(\varepsilon)$. Applying Laplace's formula to the stated row leads to the expression of $\det M_{ij}$ we used.}
\end{proof}

\begin{lemma}[{\cite[Lemma 1.1.3]{dubrovin2005}}]
\label{lemma:poisson_cohomology_is_loc_trivial}
	Let $\Pi$ be a Poisson structure of constant rank $2m$ on a $(2m+k)$-dimensional smooth manifold $M$. Locally, in a sufficiently small open ball (in the topological sense, i.e. homeomorphic to a ball of suitable dimension) $U \subseteq M$:
	\begin{enumerate}
		\item if $\overline X \in H^1_\Pi(U)$, then $\overline X = 0$ (i.e. the Poisson vector field $X$ is Hamiltonian) if and only if $X = \Pi^\sharp \eta$ for some $\eta \in \Omega^1$ (i.e. the vector field $X$ is tangent to the leaves of the symplectic foliation),
		\item if $\overline\Delta \in H^2_\Pi(U)$, then $\overline\Delta =0$ (i.e. the first-order deformation given by $\Delta$ is trivial) if and only if $\Delta(dc_1, dc_2)=0$ for any $c_1, c_2 \in \Cas(U, \Pi)$ (i.e. is zero on the Casimirs).
	\end{enumerate}
\end{lemma}
\begin{proof}
	\leavevmode
	\begin{enumerate}
		\item If $\overline X =0$, then $X = \Pi^\sharp(df)$ for some $f \in \Cinfty(M)$, then of course $X \in \im \Pi^\sharp$. Conversely, suppose $X \in \im \Pi^\sharp$. Let's start by putting Darboux--Weinstein coordinates $x^i = (q^j, p^h, c^\ell)$ on $U$ of $M$, with $c^j$ independent Casimirs. Use the Casimir coordinates to foliate the ball in symplectic leaves. We'll denote with $U_c$ the symplectic leaf where Casimirs have a fixed value $c \in \R^k$. Then on any of these, $\Pi\vert_{U_c} = \partial_{q^i} \wedge \partial_{p^i}$. Consider now its transpose, which is simply Darboux $2$-form $\omega_c = dq^i \wedge dp^i$. Extending $\omega_c$ on the whole ball $U$, we would get a closed form, even if not a symplectic one. Now, since $[\Pi, X] = 0$ then $\Lie{X}\omega_c=0$ as well, thus:
		\begin{eqalign}
			\Lie{X}\omega_c = d\ipr{X}\omega_c + \ipr{X}d\omega_c = d\ipr{X}\omega_c = 0.
		\end{eqalign}
		Then, locally on $U_c$, $\iota_X \omega_c = df_c$ where $f_c \in \Cinfty(U_c)$. We can write then
		\begin{eqalign}
			\iota_X \omega = df + \text{transverse\footnotemark\ part} \in \Omega^1(U),
		\end{eqalign}
		\footnotetext{Here and in the following ``transverse'' means along the $k$ directions of degeneracy of the Poisson structure. Hence such piece should be in the form $\phi_i dc^i$ for some functions $\phi_1, \dots, \phi_k$.}
		where $f(q,p,c) := f_c(q,p) \in \Cinfty(U)$. Remember, now, that $\iota_-\omega$ is the inverse of $\omega^{-1} = \Pi\vert_{U_c}^\sharp$. Thus, leafwise
		\begin{eqalign}
			X\vert_{U_c} &= \Pi\vert_{U_c}^\sharp(\iota_X\omega)\\
			&= \Pi^\sharp\vert_{U_c}(df\vert_{U_c} +\text{transverse part})\\
			&= \Pi^\sharp\vert_{U_c}(df_c) + \underbrace{\Pi^\sharp\vert_{U_c}(\text{transverse part})}_{\text{$=0$ by def.}}
		\end{eqalign}
		 Thus, since the symplectic foliation of $U$ partitions $U$, we get $\Pi^\sharp(df) = [\Pi, f] = X$.
		\item If $\overline \Delta = 0$, then $\Delta = \mathcal{L}_X\Pi= [X,\Pi]$ for $X \in \fields(U)$, so that for $c_1,c_2 \in \Cas(U)$
		\begin{eqalign}
			\Delta(dc_1, dc_2) &= \left(\mathcal{L}_X\Pi\right)(dc_1,dc_2)\\
			&=\Lie{X}(\Pi(dc_1,dc_2)) - \Pi(\Lie{X}dc_1,dc_2) - \Pi(dc_1,\Lie{X}dc_2)\\
			&=\Lie{X}(\cancel{\{c_1,c_2\}})- \Pi(d(X(c_1)),dc_2) - \Pi(dc_1,d(X(c_2)))\\
			&=-\{X(c_1),c_2\}-\{c_1,X(c_2)\}=0
		\end{eqalign}
		as stated.

		Conversely, choose Darboux--Weinstein coordinates $x^i = (q^j, p^h, c^\ell)$. Consider the $k$ vectors given by the components of $\Delta$ in the transverse directions:
		\begin{eqalign}
			X_a = \Delta^{ia} \pder{}{x^i}, \quad 2m+1 \leq a \leq 2m+k.
		\end{eqalign}
		In this proof the index $a$ always runs in these values. Since $\Delta$ is zero on Casimirs, this means $X_a^{i} = 0$ for $i=2m+1,\ldots,2m+k$, therefore $X_a\in \im(\Pi^\sharp)$ since it is
		tangent to the symplectic leaves of $\Pi^\sharp$.

		Now, let us compute explicitly the components of $[\Pi, \Delta]$ and of $[\Pi, X_a]$.
		One finds by direct computation (using Equation~\eqref{eq:local_form_SNB} and definition of $X_a$)
		\begin{eqalign}
		 	[\Pi,\Delta]^{i_1i_2i_3}=&\Pi^{ji_1}\partial_j\Delta^{i_2i_3}+\Pi^{ji_2}\partial_j\Delta^{i_3i_1}+\Pi^{ji_3}\partial_j\Delta^{i_1i_2}\\
			&+\Delta^{ji_1}\partial_j\Pi^{i_2i_3}+\Delta^{ji_2}\partial_j\Pi^{i_3i_1}+\Delta^{ji_3}\partial_j\Pi^{i_1i_2},
		\end{eqalign}
		\begin{eqalign}
			[\Pi, X_a]^{k_1k_2} = \Pi^{ji_1}\partial_j\Delta^{i_2a} + \Pi^{ji_2}\partial_j\Delta^{ai_1} + \Delta^{ja}\partial_j\Pi^{i_1i_2}
		\end{eqalign}
		and using $\Pi^{ia}=\Pi^{ai}=0$:
		\begin{eqalign}
		 	[\Pi,\Delta]^{i_1i_2a}=\Pi^{ji_1}\partial_j\Delta^{i_2a}+\Pi^{ji_2}\partial_j\Delta^{ai_1}+\Delta^{ja}\partial_j\Pi^{i_1i_2} = [\Pi, X_a]^{i_1i_2}.
		\end{eqalign}
		Now, by hypothesis $[\Pi,\Delta]=0$, so we find
		\begin{eqalign}
			\Lie{X_a}\Pi=0,
		\end{eqalign}
		that is $\{X_a\}$ are Poisson vector fields: $\overline{X_a}\in H^1_\Pi(U)$.

		Therefore, we just built $k$ vector fields $X_a$ such that
		\begin{enumerate}
			\item $\overline{X_a}\in H^1_\Pi(U)$;
			\item $X_a\in\im(\Pi^\sharp)$,
		\end{enumerate}
		so by the previous point, $X_a = [\Pi, f_a]$ for some $f_a \in \Cinfty(U)$.
		In local coordinates this reads $\Delta^{i\,a} = \Pi^{ji}\partial_j f_a$.
		
		Let us now change representative for this cohomology class, taking $\Delta^\prime=\Delta-[\Pi,Z]$ as the new one, where we defined \textit{ad hoc} the vector field
		\begin{equation}
			Z:=\sum_{\ell=1}^k f_{2m+\ell}\pder{}{c^\ell}.
		\end{equation}

		Let us show why this is convenient. By direct computation one finds
		\begin{equation}
			[\Pi,Z]^{ia}= \Pi^{ji}\partial_j f_a = \Delta^{ia},
		\end{equation}
		which implies that now the new representative is such that
		\begin{equation}
		\label{eq:Delta_vanish_along_casim}
			\Delta^{\prime\,ia}=\Delta^{\prime\,ai}=0.
		\end{equation}
		Now we want to prove that $\Delta^\prime$ is exact. The rest of the proof repeats the argument of the first part. 
		
		Equation~\eqref{eq:Delta_vanish_along_casim} means that $\Delta^\prime$ only has non-zero components along $\partial_{q^i}$ and $\partial_{p^i}$ directions, that is $\Delta^{\prime\sharp}$ can be really ``restricted'' to the symplectic leaves $U_c$, for all $c\in U$:
		\begin{equation}
			\Delta^{\prime\sharp}_c := \Delta^{\prime\sharp}\vert_{U_c}:\Omega^1(U_c)\longrightarrow\fields(U_c).
		\end{equation}

		This allows us to lower the indices of $\Delta^\prime$ and define, said $\omega=dq^i\wedge dp^i$,
		\begin{eqalign}
			\delta:=\omega\circ\Delta^\prime\circ\omega\in\Omega^2(U)
		\end{eqalign}
		whose components are
		\begin{eqalign}
			\delta_{ij}:=\omega_{i k}\Delta^{\prime\,kl}\omega_{lj},
		\end{eqalign}
		and correspondingly we have the leaf-restricted version
		\begin{equation}
			\delta_c := \delta \vert_{U_c} =\omega_c\circ\Delta^\prime_c\circ\omega_c	\quad	\forall c\in U.
		\end{equation}
		where $\omega_c := \omega\vert_{U_c}$. 
		
		Now, $\Pi_\epsilon=\Pi+\epsilon\Delta^\prime$ is Poisson at first order in $\epsilon$ if and only if $[\Pi, \Delta^\prime]=0$, and this is true by hypothesis. Moreover, we know $\Pi_c$ is symplectic and $\Delta^\prime_c$ is well defined, therefore $\Pi_\epsilon\vert_c=\Pi_c+\epsilon\Delta^\prime_c$ is Poisson if and only if $[\Pi\vert_c,\Delta_c]=0$, which is true by hypothesis, and since
		\begin{equation}
			\Pi_\epsilon\vert_c^{-1}=\omega_\epsilon\vert_c=\omega_c-\epsilon\omega_{\bullet h}\Delta^{hl}\omega_{l\bullet}+\mathcal{O}(\epsilon^2)
		\end{equation}
		then $\omega_\epsilon\vert_c$ is symplectic if and only if $d\omega_\epsilon\vert_c=0$, that is iff $d\delta_c=0$, which shows that $\delta_c$ is closed on the symplectic leaves $U_c$.

		Therefore, analogously to what we did in point 1. of this proof, by Poincarè lemma $d\delta_c$ is locally exact:
		\begin{equation}
			\delta_c=d\phi_c	\quad 	\exists\phi_c\in\Omega^1(U_c)\quad\forall c\in U
		\end{equation}
		so that, going back outside the leaves, $\delta=d\phi+\tilde{\delta}$ for some $\tilde{\delta}\in\Omega^2(U)$, where $\phi(q,p,c)=\phi_c(q,p)$ and $\tilde{\delta}$ contains at least one $dc^a$ in each summand. 
		
		Now, to recover $\Delta^\prime$ we compose the identity $\delta=d\phi+\tilde{\delta}$ with $\Pi$ on both sides:
		\begin{equation}
			\underbrace{\Pi\delta\Pi}_{\Delta^\prime}=\Pi d\phi\Pi+\underbrace{\Pi\tilde{\delta}\Pi}_{0}
		\end{equation}
		so $\Delta^\prime=\Pi d\phi\Pi$, and by direct computations one finds that\footnote{Recall that components $\Pi^{ij}$ are constant in D-W coordinates, i.e. $\partial_k\Pi^{ij}=0$.}
		\begin{equation}
			\Pi d\phi \Pi=[\Pi,\Pi(\phi)] \comment{where}\footnote{$\Pi(\phi)=(\frac{\Pi^{ij}}2\partial_i\wedge\partial_j)(\phi_k dx^k)=\Pi^{ij}\phi_j\partial_i\in\fields(M)$} \quad \Pi(\phi) = \Pi^{ij}\phi_j\partial_i
		\end{equation}
		that is $\Delta^\prime=[\Pi,\Pi(\phi)]\in\im[\Pi, \bullet]$. This proves that $\overline{\Delta^\prime}=0$, as we wanted.
	\end{enumerate}
\end{proof}

\begin{corollary}[{\cite[Corollary 1.2.8]{dubrovin2005}}]
	Let $\Pi_0 + \varepsilon \Pi_1$ be a Poisson pencil of constant rank for small $\varepsilon$ and on some ball $U \subseteq M$. Then
	\begin{eqalign}
		\overline \Pi_1 = 0 \in H^2_{\Pi_0}(U).
	\end{eqalign}
\end{corollary}
\begin{proof}
	From Lemma~\ref{lemma:comp_poisson_of_const_rank_same_cas} we know $\Pi_1$ vanishes on the Casimirs of $\Pi_0$, hence the corollary follows from the second claim of Lemma~\ref{lemma:poisson_cohomology_is_loc_trivial}.
\end{proof}

The meaning of the last result is that if $(\Pi_0, \Pi_1)$ forms a Poisson pencil of constant rank, then we can locally reabsorb any deformation of $\Pi_0$ by $\Pi_1$ with a coordinate change.

\begin{theorem}[{\cite[Theorem 1.2.9]{dubrovin2005}}]
	Let $\Pi_\varepsilon = \Pi_0 - \varepsilon \Pi_1$ be a Poisson pencil of constant\footnote{Constant respect both $\varepsilon\ll1$ and $p\in M$. This ensures the existence of $k$ Casimir for each value of $\varepsilon$.} rank for small $\varepsilon$ on a ball $U$ on the manifold $M$. Let $c^1(\varepsilon), \ldots, c^k(\varepsilon)$ be $k = \cork(\Pi_0) = \cork(\Pi_\varepsilon)$ independent Casimirs for $\Pi_\varepsilon$ and let\footnote{We label the components of $c^i$ starting from $-1$ since the first component is usually trivial.}
	\begin{eqalign}
	\label{eq:casimir_taylor_exp}
		c^i(\varepsilon) = c^i_{-1} + c^i_0\varepsilon + c_1^i\varepsilon^2 + \ldots
	\end{eqalign}
	be their Taylor expansion in $\varepsilon$ around $\varepsilon = 0$ (it's a power series of $\varepsilon$). Then the sequences $\seq{c^i}{p}$ are in Hamiltonian recursion, and moreover they \textbf{all} commute with each other with respect to both brackets:
	\begin{eqalign}
		\{c^i_p, c^j_q\}_0 = \{c^i_p, c^j_q\}_1 = 0
	\end{eqalign}
\end{theorem}
\begin{proof}
	Since $c^i(\varepsilon)$ is a Casimir of $\Pi_\varepsilon$,
	\begin{eqalign}
		0 &= \Pi(\varepsilon)^\sharp(dc^i(\varepsilon))\\
		&= \{\bullet,c^i(\varepsilon)\}_\varepsilon\\
		&= \{\bullet, c^i(\varepsilon)\}_0 - \varepsilon \{\bullet,c^i(\varepsilon)\}_1\\
		&= \left( \sum_{p=-1}^{\infty} \{\bullet,c^i_p(\varepsilon)\}_0 \varepsilon^{p+1} \right) - \varepsilon\left( \sum_{p=-1}^{\infty} \{\bullet,c^i_p(\varepsilon)\}_1 \varepsilon^{p+1} \right)\\
		&= \sum_{p=-1}^{\infty} (\{\bullet,c^i_p\}_0 - \{\bullet,c^i_{p+1}\}_1)\varepsilon^{p+1}
	\end{eqalign}
	where we set $c^i_{-2} := 0$. Then the fact all the coefficients of the above power series vanish correspond to the wanted recursion relation. Theorem~\ref{th:magri} takes care of the commuting relations among each of the $k$ sequences $\seq{c^i}{p}$, so we just need to prove the functions commute also when in different sequences. To do this, we turn the trick we used for Magri's Theorem on its head: we spread the functions apart until one of them hits $-1$, at which point we can use the fact $c^i_{-1}$ is Casimir at $\varepsilon =0$ (because the rest of the terms of \eqref{eq:casimir_taylor_exp} vanish):
	\begin{eqalign}
		\{c^i_p, c^j_q\}_0 &= \{c^i_p, c^j_{q-1}\}_1\\
		&= -\{c^j_{q-1}, c^i_p\}_1\\
		&= -\{c^j_{q-1}, c^i_{p+1}\}_0\\
		&= \{c^i_{p+1}, c^j_{q-1}\}_0\\
		&= \ldots\\
		&= \{c^i_{p+q+1}, c^i_{-1}\}_0 = 0
	\end{eqalign}
\end{proof}

Hence the ``canonical way'' to get an Hamiltonian recursion out of a bihamiltonian structure of constant rank is to find the Taylor expansion of the Casimirs. \textbf{How do we find it?}

\begin{construction}[{\cite[Example 1.2.10]{dubrovin2005}}]
	One strategy goes like this. We have shown that if $\Pi_0-\varepsilon\Pi_1$ is a Poisson pencil of constant rank, then $\overline \Pi_1 = 0 \in H_{\Pi_0}^2(U)$. This means $\Pi_1 = \Lie{Z}\Pi_0$ for some $Z \in \fields^1(U)$. Let us make the additional assumption that $\Lie{Z}^2\Pi_0 = 0$, i.e. the Poisson pencil is \textbf{exact}.

	Let's chose a fixed coordinate patch in such a way that $Z = \partial_1$, i.e. $Z$ corresponds to the shift along $x^1$. Then $\Pi_0^{ij}$ will depend linearly on $x^1$ (since the second derivative vanishes), while $\Pi_1^{ij}$ will be independent of it (since $\Lie{\partial_1} \Pi_1 = \Lie{\partial_1}\Lie{\partial_1}\Pi_0 = 0$). This means that, if $\mathsf{shift}^1_\varepsilon$ is the change of coordinates sending $x_1$ to $x_1 - \varepsilon$, then
	\begin{eqalign}
		\mathsf{shift}^1_\varepsilon(\Pi_0)^{ij} = \Pi_0^{ij} - \varepsilon \Pi_1^{ij} = \Pi_\varepsilon^{ij}.
	\end{eqalign}
	This shows that the Casimirs of $\Pi_\varepsilon$ are $c^i(\varepsilon) = \mathsf{shift}^1_\varepsilon(c^i_{-1})$, hence we have a simple way to get the desired functions from the Casimirs of $\Pi_0$:\footnote{This follows from $c_{-1}^i\in\Cas(\Pi_0)$ and $\Pi_\varepsilon = \mathsf{shift}^1_\varepsilon(\Pi_0)$.}
	\begin{eqalign}
		c^i(\varepsilon) = \exp(\varepsilon Z)c^i_{-1} = c^i_{-1} + \varepsilon Z(c^i_{-1}) + \frac{\varepsilon^2}2 Z(Z(c^i_{-1})) + \ldots
	\end{eqalign}
\end{construction}

\begin{example}[Toda lattice]
	Remember Toda's equations from Example~\ref{ex:toda_lattice} (we rescaled them by a factor, $t\mapsto t/2$,  to get nicer numbers later on):
	\begin{eqalign}
		\begin{cases}
			\dot{a}_i = a_i (b_{i+1} - b_i)\\
			\dot{b}_i = 2(a_i^2 - a_{i-1}^2)
		\end{cases}
	\end{eqalign}
	Geometrically, we think of $a_1, \ldots, a_{n-1}$ and $b_1, \ldots, b_n$ as coordinates on a manifold. We equip it with a Poisson structure by setting
	\begin{eqalign}
	\label{eq:poiss_struct_toda}
		\{a_i, b_i\}_1 = -a_i \quad , \quad \{a_i, b_{i+1}\}_1 = a_i
	\end{eqalign}
	and zero in every other case.

	Usually, one gets the $a_i$s and the $b_i$s from another set of (physical) coordinates $(p_i, q_i)$ by the following change of variables:
	\begin{eqalign}
		\begin{dcases}
			a_i = \frac12 \e^{\frac12 (q_i - q_{i+1})}\\
			b_i = -\frac12 p_i
		\end{dcases}
	\end{eqalign}
	With respect to those coordinates, the bracket is just $\{q_i, p_j\}_1 = \delta_{ij}$. The Hamiltonian of the system is
	\begin{eqalign}
		H = \frac12 (b_1^2 + \ldots + b_n^2) + a_1^2 + \ldots + a_{n-1}^2.
	\end{eqalign}
	The interpretation for this Hamiltonian is that the first term is a kinetic energy term while the second is a potential energy term for an exponential potential which is defined among neighbouring particles. The system has also a Lax representation as
	\begin{eqalign}
		L &= \begin{pmatrix}
			b_1 & a_1 & & & 0\\
			a_1 & & \ddots & & \\
			& & \ddots & & \\
			& & \ddots & & a_{n-1}\\
			0 & & & a_{n-1} & b_{n-1}
		\end{pmatrix}\quad,\quad
		B &= \begin{pmatrix}
			0 & a_1 & & & 0\\
			-a_1 & & \ddots & & \\
			& & \ddots & & \\
			& & \ddots & & a_{n-1}\\
			0 & & & -a_{n-1} & 0
		\end{pmatrix}
	\end{eqalign}
	such that $\der{L}{t} = -[L, B]$. In lieu of $B=RL$ we have $B=\pr_-(L) = \overline{u}(L) - \overline{u}(L)^T$, but it is the same thing as
	\begin{eqalign}
		R = \pr_+ - \pr_- = \pr_+ \pr_- - 2\pr_- = \id - 2\pr_-.
	\end{eqalign}
	The symmetries of the system are given by the trace of $L$, $b_1 + \ldots + b_n$. It is a Casimir function since
	\begin{eqalign}
		\{\trace L, b_i\}_1 &= 0,\\
		\{\trace L, a_i\}_1 &= \{b_1, a_i\}_1 + \ldots + \{b_i, a_i\}_1 + \{b_{i+1}, a_i\}_1 + \ldots + \{b_n, a_i\}_1\\
		&= 0 + \ldots + 0 + \cancel{-a_i + a_i} + 0 + \ldots + 0 = 0.
	\end{eqalign}
	This, and the traces of higher powers of $L$, are the symmetries of the lattice (but only the first is a Casimir):
	\begin{eqalign}
		H_{-1} &= \trace L = b_1+\dots+b_n \comment{Casimir}\\
		H_0 &= \frac12\trace L^2 = \frac12(b_1^2+\dots+b_n^2) + a_1^2 + \dots + a_{n-1}^2 \comment{Hamiltonian}\\
		H_1 &= \frac13 \trace {L^3}\\
		&\ \, \vdots
	\end{eqalign}

	We now give a second Hamiltonian structure to the system, by providing new Poisson brackets. The pivotal observation is that the bracket we just defined is independent from the $b_i$ coordinates, as we see from the definition (a $b_i$ coordinate never appears on the right hand side of Equations~\eqref{eq:poiss_struct_toda}). So we guess (there are actually good theoretical reason for this) there might be a second compatible Poisson bracket linearly dependent on the $b_i$s, to which we could then apply the machinery we just derived for this case. So we start by adding a linear dependence on $b_i$s:
	\begin{eqalign}
		\{a_i, b_i\}_2 = -a_ib_i, \quad \{a_i, b_{i+1}\}_2 = a_ib_{i+1}
	\end{eqalign}
	and then we correct the rest of the terms in order to satisfy the Jacobi identity:
	\begin{eqalign}
		\{a_i, a_{i+1}\}_2 = \frac12 a_i a_{i+1}, \quad \{b_i,b_{i+1}\}_2 = 2a_i^2.
	\end{eqalign}
	So the Poisson pencil is exact (because $\Pi_1$ is independent of the $b_i$ and $\Pi_2$ depends only linearly on them), and
	\begin{eqalign}
		Z = \sum_{i=1}^n \partial_{b_i}.
	\end{eqalign}
	One can show $\det L$ is a Casimir for $\{\bullet,\bullet\}_2$, and we get $\mathsf{shift}^1_\varepsilon(\det L)= \det (L-\varepsilon I)$, hence $\det (L-\varepsilon I)$ is a Casimir for $\{\bullet,\bullet\}_\varepsilon$. This latter object is the characteristic polynomial of $L$ evaluated at $\varepsilon$, thus the coefficients of its Taylor expansion in $\varepsilon$ coincides with its coefficient as a polynomial, are exactly $n$ and given by the traces of successive powers of $L$.
\end{example}

The situation of this example is general: given an $R$-matrix for a Lie--Poisson structure, there's a canonical way to construct a second (and actually even a third) compatible quadratic Poisson structure. The spectral invariants we get from the Lax representation are then in Hamiltonian recursion for this pair of Poisson structures.

\section{The Hamiltonian recursion in the symplectic case}
In the case one of the Poisson is symplectic, we do not have enough Casimir functions\footnote{This is especially true for the constant rank case: in fact, under this assumption the non-degeneracy of one Poisson structure forces non-degeneracy in the other, so we really do not have any Casimir.} so we need a different approach.

\subsection{Nijenhuis structures}
For this section, we refer to \cite{magri1984geometrical}. In this seminal paper, Magri and Morosi set out the theory of Poisson--Nijenhuis geometry, which deals with ``compatible'' tensor structures of Poisson, Nijenhuis and symplectic type. The article obtains hierarchies of symmetries out of this especially nice situation, through the method of Hamiltonian recursions.

\begin{definition}
	The \textbf{Nijenhuis torsion} is the operator $T(N) : \fields(M) \tens \fields(M) \to \fields(M)$ defined $\forall X,Y \in \fields(M)$ by
	\begin{eqalign}
		T(N)(X,Y) &= [NX, NY] - N([NX, Y] + [X,NY]) + N^2[X,Y]\\
		&= [NX, NY] + N(\Lie Y(N)X - \Lie X(N)Y) - N^2[X,Y]\\
		&= \Lie{NX}(N)Y - N\Lie{X}(N)Y
	\end{eqalign}
	where $N \in \fields^1_1(M)$.
\end{definition}

\begin{definition}
	A tensor field $N \in \fields^1_1(M)$ is called \textbf{Nijenhuis} if it satisfies $T(N) = 0$.
\end{definition}

The Nijenhuis torsion embodies the obstruction to some sort of compatibility between the Lie derivative and the field $N\in\fields^1_1(M)$. When $N$ is Nijenhuis such compatibility is archived and
\begin{eqalign}
\label{eq:nijenhuis_prop}
	\Lie{NX}(N) = N\Lie{X}(N), \quad\forall X \in \fields(M).
\end{eqalign}

\begin{definition}
	A \textbf{Nijenhuis manifold} is a smooth manifold $M$ equipped with a Nijenhuis tensor $N$.
\end{definition}

However, the most interesting situation comes when a Nijenhuis structure coexists (nicely) with a symplectic or Poisson structure:

\begin{definition}
	A \textbf{symplectic--Nijenhuis manifold} $M$ is a symplectic manifold $(M, \omega)$ equipped with a Nijenhuis tensor $N$ such that\footnote{We denote by $N^* : T^*M \to T^*M$ the transposed map respect to $N$.}
	\begin{eqalign}
	\label{eq:symp_nijenhuis_conditions}
		S(\omega, N) = 0, \quad \omega N - N^*\omega = 0.
	\end{eqalign}
	where $S$ is an operator defined as
	\begin{eqalign}
		S(\eta, Q)(X,Y) := \Lie{QY}(\eta)X - \Lie{QX}(\eta)Y + \eta Q[X,Y] + d\langle \eta Q Y,X \rangle, \quad X,Y \in \fields(M).
	\end{eqalign}
\end{definition}

The first condition is a compatibility, \emph{a fortiori} condition, which arises from computation regarding how Hamiltonian vector are preserved by the Nijenhuis tensor (it basically implies that the symmetries arising from Lemma~\ref{lemma:fund_fields_of_nijenhuis} can be Hamiltonian if we start with Hamiltonian fields). The second condition expresses antisymmetry for $\omega N$, where the spurious minus sign comes from the antisymmetry of $\omega$ itself. In the case $N=\Pi\omega$, then it is fullfilled and it's really an antisymmetry condition (since $\omega\Pi\omega$ is the composition of an odd number of antisymmetric tensors, thus antisymmetric itself).

\begin{definition}
	A \textbf{Poisson--Nijenhuis manifold} is a Poisson manifold $(M,\Pi)$ equipped with a Nijenhuis tensor $N$ such that
	\begin{eqalign}
	\label{eq:poisson_nijenhuis_conditions}
		R(\Pi,N) = 0, \quad N\Pi - \Pi N^* = 0
	\end{eqalign}
	where $R$ is an operator defined as
	\begin{eqalign}
		R(P,Q)(\alpha, X) := \Lie{P\alpha}(Q)X - P\Lie{X}(Q^* \alpha) + P\Lie{QX}\alpha, \quad \alpha \in \Omega^1(M), X \in \fields(M).
	\end{eqalign}
\end{definition}

The first intriguing geometric result about these structures is that any ``symplectic--Poisson'' manifold can be given the structure of both a symplectic--Nijenhuis manifold, by defining $N=\Pi\omega$, and that of a Poisson--Nijenhuis manifold, by setting $\omega = \Pi^{-1}N$ (actually, in the case that $\Pi$ is non-degenerate).

\begin{lemma}
\label{lemma:powers_of_comp_are_closed}
	Let $\Pi$ be a Poisson structure on $M$ and $\omega$ a compatible symplectic form, i.e. $[\Pi, \omega^{-1}]=0$. Then\footnotemark
	\begin{eqalign}
		d((\omega\Pi)^n \omega) = 0, \quad \forall n \in \N.
	\end{eqalign}
\end{lemma}
\footnotetext{Let's clarify the notation. The object $\omega\Pi\omega$ is the map defined by
\begin{eqalign}
	\omega\Pi\omega : TM \overset{\omega^\sharp}\longto T^*M \overset{\Pi^\sharp}\longto TM \overset{\omega^\sharp}\longto T^*M
\end{eqalign}
and similarly we get $(\omega\Pi)^n \omega \in \Omega^2(M)$. Then $d((\omega\Pi)^n \omega)\in \Omega^3(M)$ is the usual exterior derivative.}
\begin{proof}
	Since $\omega$ is compatible with $\Pi$, $(\omega^{-1}, \Pi)$ is a bihamiltonian structure. In particular, $\omega^{-1}-\varepsilon \Pi$ is Poisson and non-degenerate if $\varepsilon$ is sufficiently small, so that $(\omega^{-1}-\varepsilon \Pi)^{-1}$ is symplectic, and
	\begin{eqalign}
		(\omega^{-1}(1-\varepsilon \omega \Pi))^{-1} = \left(\sum_{n=0}^\infty (\varepsilon \omega \Pi)^n \right) \omega = \omega + \varepsilon \omega \Pi \omega + \varepsilon^2 \omega \Pi \omega \Pi \omega + \ldots.
	\end{eqalign}
	Because symplectic implies closed, and $d$ it's a linear operator, the above expression gives the thesis for every value of $n \in \N$.
\end{proof}

\begin{proposition}[\cite{magri1984geometrical}]
	Let $\Pi$ be a Poisson tensor and $\omega$ a symplectic form on some manifold $M$, such that $d(\omega\Pi\omega) = 0$. Then:
	\begin{enumerate}
		\item $T(\Pi\omega)=0$, i.e. $\Pi\omega$ is a Nijenhuis tensor;
		\item the symplectic manifold $(M, \omega)$ equipped with $\Pi\omega$ is a symplectic-Nijenhuis manifold;
		\item the Poisson manifold ($M, \Pi$) equipped with $\Pi\omega$ is a Poisson-Nijenhuis manifold;
		\item $d((\omega\Pi)^n\omega)=0$, $\forall n \in \N$, i.e. we have an infinite number of symplectic structures on $M$;
		\item $[(\Pi\omega)^n\Pi, (\Pi\omega)^m\Pi]=0$, $\forall n,m\in\N$, i.e. we have an infinite number of Poisson structures on $M$.
	\end{enumerate}
\end{proposition}
\begin{proof}
	The proof rests on the following identities, whose lengthy proof can be found in \cite[Appendix B.3]{magri1984geometrical}: given  $P \in \Lambda^2(M)$, $Q \in \fields_1^1(M)$ and $\eta \in \Omega^2(M)$,
	\begin{eqalign}
		R(P, P\eta)(\alpha, X) &= [P,P](\eta X, \alpha)+P\,d\eta(P\alpha, X)\\
		S(\eta, Q)(X,Y) &= d\eta(QX,Y)+d\eta(QY,X)+d(\eta Q)(X,Y)\\
		T(P\eta)(X,Y) &= [P,P](\eta X, \eta Y) - PS(\eta,P\eta)(X,Y)
	\end{eqalign}
	For instance, for the first point, when $P = \Pi$ and $\eta = \omega$, we have $[\Pi, \Pi] = 0$ as $\Pi$ is Poisson, $d\omega = 0$ as $\omega$ is symplectic, and $d(\Pi\Omega) = 0$ by hypothesis, therefore all the terms of $T(\Pi\omega)$ vanish, as claimed.
\end{proof}

Indeed symplectic, Poisson and Nijenhuis structures dance around each other in an interesting way:

\begin{center}
	\begin{tabular}{c|c|c|l}
		\textbf{Symplectic} & \textbf{Poisson} & \textbf{Nijenhuis} & \textbf{given that}\\[1ex]
		\hline
		$\omega$ & $\Pi$ & $\Pi\omega$ & $d(\omega\Pi\omega) = 0$\\[1ex]
		$\omega$ & $N\omega^{-1}$ & $N$ & Conditions~\eqref{eq:symp_nijenhuis_conditions}\\
		$\Pi^{-1}N$ & $\Pi$ & $N$ & Conditions~\eqref{eq:poisson_nijenhuis_conditions} + $\Pi$ is non-degenerate.
	\end{tabular}
\end{center}

But even more interesting is the fact that symplectic-- and Poisson--Nijenhuis manifolds actually come in well-behaved hierarchies: starting from $(\omega, N)$ or $(\Pi, N)$ we can define new structures of the same type by iterated composition:
\begin{eqalign}
	P_{k+1} = N^k P, \quad \Omega_{k+1} = \Omega N^k.
\end{eqalign}
This in turn originates from the fact that Nijenhuis structures come in hierarchies, given again by iterated composition (so that when $(M,N)$ is Nijenhuis manifold, so is $(M, N^k)$ for any $k \in \N$).

% Let's start to put this machinery at the disposal of integrability theory. The first step is to develop a theory of ``Hamiltonian'' vector fields for Nijenhuis structures, in parallel with symplectic and Poisson manifolds.

% \begin{definition}
% 	Let $(M,N)$ be a Nijenhuis manifold, and let $N^*$ be the transpose\footnote{Which means $\langle NX, \alpha \rangle = \langle X, N^*\alpha \rangle$.} of $N$. A \textbf{fundamental form} for the Nijenhuis tensor is a closed form $\alpha \in \Omega^1(M)$ such that
% 	\begin{eqalign}
% 		dN^*\alpha = 0.
% 	\end{eqalign}
% \end{definition}
% \begin{definition}
% 	A \textbf{fundamental field} on a Poisson--Nijenhuis manifold $(M,N,\Pi)$ is the image of a fundamental form through the $\Pi$-sharp operator:
% 	\begin{eqalign}
% 		X = \Pi^\sharp(\alpha), \quad dN^*\alpha = 0, \quad d\alpha = 0.
% 	\end{eqalign}
% \end{definition}

% \begin{proposition}
% 	The fundamental fields of $(M,N,\Pi)$ are exactly those which preserve both the Poisson and the Nijenhuis structure.
% \end{proposition}
% \begin{proof}

% \end{proof}

\begin{lemma}
\label{lemma:fund_fields_of_nijenhuis}
	Let $N$ be Nijenhuis and let $\{X_1, \ldots, X_n, \ldots\}$ be a system of vector fields in involution and preserving $N$ ($\Lie{X_i}N=0$ for any $n$). Then
	\begin{eqalign}
		[N^k X_i, N^h X_j] = 0,
	\end{eqalign}
	where exponents denote repeated application.
\end{lemma}
\begin{proof}
	We get the claim by repeated applications of the Leibniz rule, and in the last step using Equation~\ref{eq:nijenhuis_prop}:
	\begin{eqalign}
		[N^k X_i, N^h X_j] &= \Lie{N^kX_i}(N^h X_j)\\
			&= \Lie{N^k X_i}(N^h)X_j + N^h \Lie{N^k X_i}(X_j)\\
			&= \left(\sum_{n=0}^{h-1} N^n \Lie{N^k X_i}(N)N^{h-n-1} X_j\right) - N^h \Lie{X_j}(N^k X_i)\\
			&= \left(\sum_{n=0}^{h-1} N^n N^k \underbrace{\Lie{X_i}(N)}_0 N^{h-n-1} X_j\right) - N^h \underbrace{\Lie{X_j}(N^k)}_0X_i - N^{h+k}\underbrace{\Lie{X_j}{X_i}}_0\\
			&= 0.
	\end{eqalign}
\end{proof}

A peculiar fact about the hierarchy of Poisson tensors we get out of a Poisson--Nijenhuis structure is that
\begin{eqalign}
	[\Pi_i, \Pi_j] = 0, \quad \forall i,j;
\end{eqalign}
so Nijenhuis tensor become a rich source of bihamiltonian structures. Then Lemma~\ref{lemma:fund_fields_of_nijenhuis} tells us that when we find a system of commuting fields which preserve $N$, we get out a whole hierarchy of them. One can show that each vector field preserving both $N$ and $\Pi_i$ is Hamiltonian respect to $\Pi_i$, so under the hypothesis of this lemma each Hamiltonian $X_i$ is Hamiltonian with respect to each $\Pi_j$, $j \leq i$, and so are each $N^kX_i$, so the system is integrable respect to Arnold-Liouville theorem provided that at lest $\frac12\dim M$ of these fields are independent. 

\subsection{The recursion}
\begin{theorem}
	The functions
	\begin{eqalign}
		h_{p+1} := \frac1{p+1} \trace N^{p+1},
	\end{eqalign}
	for $p\in\N$ and $N:= \omega\Pi$, satisfy the recursion
	\begin{eqalign}
		dh_{p+1} = N^* dh_p.
	\end{eqalign}
\end{theorem}
\begin{proof}
	Recall contractions commute with Lie derivatives, then we compute
	\begin{eqalign}
		\langle dh_{p+1}, X\rangle = X(h_{p+1}) &= \Lie{X}h_{p+1}\\
			&= \Lie{X}\left(\trace \frac1{p+1}N^{p+1}\right)\\
			&= \frac{\cancel{p+1}}{\cancel{p+1}} \trace (N^p \Lie{X}N)\\
			&= \trace (N^{p-1}\Lie{NX}N) \comment{by using~\eqref{eq:nijenhuis_prop}}\\
			&= \Lie{NX}(\trace \frac1p N^p)\\
			&= \langle dh_p, NX \rangle\\
			&= \langle N^* dh_p, X \rangle, \quad \forall X \in \fields(M).
	\end{eqalign}
\end{proof}

\begin{remark}[{\cite[Section 1.2.2]{dubrovin2005}}]
	Notice that, when $N=\Pi\omega$, $N^* = \omega \Pi$ by antisymmetry. This means the recursion is
	\begin{eqalign}
		dh_{p+1} &= \omega\Pi dh_p\\
		\omega^{-1}(dh_{p+1}) &= \Pi(dh_p)\\
		\{\bullet,h_{p+1}\}_{\omega^{-1}} &= \{\bullet,h_p\}_\Pi
	\end{eqalign}
	that is, the operator $N^* : \Omega^1(M) \to \Omega^1(M)$ describes  the Hamiltonian recursion of Magri's Theorem!
	
	Clearly, there are at most $n=\frac12\dim M$ independent functions $h_p$, since we cannot have more than $n$ independent covectors $dh_p\vert_x$ in $T^*_xM$ because of the non-degeneracy of $\Pi_0^{-1} =\omega$. If we have $n$ independent functions Magri's Theorem tells us that they are in involution and can be used with Frobenius' Theorem to integrate $M$. 

With this theorem we found the hierarchy of symmetries we were looking for in the symplectic (non-degenerate) case of a bihamiltonian structure. In fact, if $(\Pi_0,\Pi_1)$ is a compatible pair of Poisson tensors where $\Pi_0$ is non-degenerate, $N=\Pi_1\Pi_0^{-1}$ is Nijenhuis and the hierarchy is given by the spectrum of $N$ (as per previous theorem).
\end{remark}

\end{document}