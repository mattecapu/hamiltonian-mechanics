\documentclass[main.tex]{subfiles}
\begin{document}

\chapter{Classical R-matrix and Lax representation}
The first two sections are based on \cite[Section 3]{oevel1989r}.

\section[Classical R-matrix]{Classical $R$-matrix}
\begin{definition}
	An \textbf{$R$-matrix} is a linear map $R: \lalg \to \lalg$ on a Lie algebra $\lalg$ having the property that the modified bracket
	\begin{eqalign}
		[X,Y]_R = [RX,Y]+[X,RY], \quad \forall X,Y \in \lalg
	\end{eqalign}
	defines a Lie product on $\lalg$.
\end{definition}

As customary, to the $R$-bracket on $\lalg$ is associated a Poisson bracket on $\lalg^*$:
\begin{eqalign}
	\{f,g\}_R(\xi) = \langle [df, dg]_R, \xi \rangle, \quad \forall \xi \in \lalg^*,\, \forall f,g \in \Cinfty(\lalg^*).
\end{eqalign}

\begin{proposition}
	A linear map $R: \lalg \to \lalg$ on a Lie algebra $(\lalg, [-,-])$ is an $R$-matrix if and only if
	\begin{eqalign}
		[B_R(X,Y), Z] + [B_R(Y,Z), X] + [B_R(Z,X), Y] = 0
	\end{eqalign}
	where
	\begin{eqalign}
		B_R(X,Y) = [RX, RY]- R[X,Y]_R
	\end{eqalign}
\end{proposition}
\begin{proof}
	Exercise, it's just a computation.
\end{proof}

The operator $B_R$ measures how far $R$ is from being a Lie algebra homomorphism. It is quadratic on both terms. Notice that, while $B_R = 0$ certainly satisfies the hypotheses of the theorem, it doesn't have to be the case:

\begin{corollary}
	A \emph{sufficient} condition for a linear map $R: \lalg \to \lalg$ to be an $R$-matrix is for $R$ to satisfy the \textbf{modified Yang--Baxter equation} (mYBE):
	\begin{eqalign}
		B_R(X,Y) = -c[X,Y],
	\end{eqalign}
	for some $c \in \R$.
\end{corollary}

Clearly, up to rescaling of $R$, there are actually just two cases of the mYBE: the one with $c=0$ (corresponding to the case where $R$ is an automorphism of the algebra) and the one with $c=1$. For this second case, there is a special class of solutions that arises in a very simple manner:

\begin{construction}
	Let $(\lalg, [-,-])$ be a Lie algebra which decomposes (as vector space!) as $\lalg = \lalg_+ \dir \lalg_-$, for $\lalg_\pm \leq \lalg$. We do \textbf{not} require $[\lalg_+, \lalg_+] = 0$, i.e. the direct sum does not need to be one of Lie algebras. Let $\pr_\pm$ denote the projections onto $\lalg_+$ and $\lalg_+$ respectively and write $X_\pm = \pr_\pm X$ for any vector $X \in \lalg$. Then we claim $R = \frac12 (\pr_+ - \pr_-)$ is an $R$-matrix. In fact observe that, by virtue of the bilinearity of $[-,-]$, the $R$-bracket follows the splitting perfectly:
	\begin{eqalign}
		[X,Y]_R &= \frac12 [X_+ - X_-, Y] + \frac12 [X, Y_+ - Y_-]\\
			&= \frac12 \left( [X_+ - X_-, Y_+ + Y_-] + [X_+ + X_-, Y_+ - Y_-] \right)\\
			&= \frac12 \left( [X_+, Y_+] - [X_-, Y_-]\right)
	\end{eqalign}
	Then its clear we can decompose the Jacobi identity of $[-,-]_R$ into two Jacobi identities for $[-,-]$, which hold by assumption. This class of examples is very ample as any decomposition of $\lalg$ works.
\end{construction}

Occasionally people find solutions of the mYBE which do not come from the decomposition we've treated. In fact, there are a lot of examples but the great majority of them is in the infinite-dimensional context. Indeed, this theory comes from that environment (in particular the study of PDEs), and only later it was realized there was some honest finite-dimensional geometry behind it.

\begin{proposition}
\label{prop:cas_ham_field}
	If $h \in \Cas(\lalg^*, \{-,-\})$ then its Hamiltonian vector field with respect to the Poisson $R$-bracket is
	\begin{eqalign}
		X^R_h\vert_\alpha = \ad^*_{R(dh\vert_\alpha)}\vert_\alpha.
	\end{eqalign}
\end{proposition}
\begin{proof}
	For all $f \in \Cinfty(\lalg^*)$ and $\alpha \in \lalg^*$,
	\begin{eqalign}
		X^R_h(f)\vert_\alpha &= \{f,h\}_R\vert_\alpha\\
			&= \langle [df\vert_\alpha, dh\vert_\alpha]_R, \alpha \rangle\\
			&= \langle [R(df\vert_\alpha), dh\vert_\alpha] + [df\vert_\alpha, R(dh\vert_\alpha)], \alpha \rangle\\
			&= \langle [R(df\vert_\alpha), dh\vert_\alpha], \alpha \rangle + \langle [df\vert_\alpha, R(dh\vert_\alpha)], \alpha \rangle\\
			&= \langle \ad_{R(df\vert_\alpha)}\vert_{dh\vert_\alpha}, \alpha \rangle - \langle \ad_{R(dh\vert_\alpha)}\vert_{df\vert_\alpha}, \alpha \rangle\\
			&= -\ad^*_{R(df\vert_\alpha)}(h)\vert_\alpha + \ad^*_{R(dh\vert_\alpha)}(f)\vert_\alpha
	\end{eqalign}
	Since $\ad^*_X$ is tangent to the symplectic leaves (Theorem~\ref{th:coadj_is_tangent}) and $h$ is Casimir, the first term vanishes and the claim follows.
\end{proof}

\begin{corollary}
\label{cor:cas_are_inherited}
	If $f,g, \in \Cas(\lalg^*, \{-,-\})$, then they commute with respect to the Poisson $R$-bracket.
\end{corollary}
\begin{proof}
	Since $f$ is constant on coadjoint orbits:
	\begin{eqalign}
		\{f,g\}_R = \ad^*_{R(dg)}(f) = 0.
	\end{eqalign}
\end{proof}

\begin{remark}
	The flow of $X^R_h$ for $h$ Casimir lies in the intersection of the coadjoint orbits of $(\lalg, [-,-])$ and $(\lalg, [-,-]_R)$. So it is $\ad^*$ of something but also the $\ad^*_R$ of something.
\end{remark}

\begin{remark}
	Let $(-,-)$ be an $\Ad$-invariant (bilinear, non-degenerate) form on $\lalg$. Then this provides an identification $\lalg \iso \lalg^*$ sending $\ad_X$ to $-\ad^*_X$. In this case the equations of motion (Hamilton's) become (for the $R$-matrix)
	\begin{eqalign}
		\der{X}{t} = - \ad_{R(dh)}\vert_X = [X, R(dh)].
	\end{eqalign}
\end{remark}

\begin{example}
	In the case $\lalg = \mathfrak{gl}(n)$ (the Lie algebra associated to square matrices with complex entries, but seen as a real manifold). Then $\Ad_g X = gXg^{-1}$. We consider the form $(X,Y) := \trace(XY)$. It is $\Ad$-invariant since
	\begin{eqalign}
		\trace (gXg^{-1}gYg^{-1}) &= \trace (gXY g^{-1})\\
			&= \trace (g^{-1}gXY) \comment{b.c. trace is cyclic-invariant}\\
			&= \trace XY.
	\end{eqalign}
	Some Casimir functions in $(\lalg^*, \{-,-\})$ are given by $h_i = \trace (X^i)$ (where the apex is an exponent), because any such function is $\Ad$-invariant, hence constant on (co)adjoint orbits.

	By the last remark, \emph{any} Casimir function $h$ on the Poisson algebra on $\lalg^*$ let's you find the evolution given by $X$:
	\begin{eqalign}
		\der{X}{t} =[X, R(dh)]
	\end{eqalign}
	The $h_i$, for $i=1,\ldots,n$, are in involution, so they represent symmetries of the system. These will turn out to be the most general spectral invariants of the matrix $X$.
\end{example}

These last ideas will be applied in the informative example of the Toda lattice (Example~\ref{ex:toda_lattice}).

\begin{center}
	------------------------
\end{center}

Given an $\Ad$-invariant form $(-,-)$ and an $R$-matrix, then if $h \in \Cinfty(\lalg^*)$ from the computation of Lemma~\ref{prop:cas_ham_field} we get:
\begin{eqalign}
\label{eq:evolution_in_an_R_system}
	\der{X}{t} = [X, R \nabla h] + R^*[X, \nabla h]
\end{eqalign}
where $R^*$ is the $(-,-)$-adjoint of $R$ ($(RX, Y) = (X, R^*Y)$). If $h$ is Casimir on $\lalg^*$ the second term drops, as we've seen above. Alternatively, in terms of adjoint actions:
\begin{eqalign}
	X^R_h(f)\vert_\alpha = \ad^*_{R(dh\vert_\alpha)}(f)\vert_\alpha - \ad^*_{R(df\vert_\alpha)}(h)\vert_\alpha.
\end{eqalign}
In Equation~\eqref{eq:evolution_in_an_R_system}, we could put any $A \in \lalg$ in lieu of $\nabla h$, interpreted as a $1$-form \what.

Every other Casimir provides an integral of motion and they all commute. In the case of $\mathfrak{gl}(n)$, or its Lie subalgebras, a set of Casimirs is given by $h_i = \trace X^i$.

\section{Lax Representations}
\begin{definition}
	Given a vector field $X \in \fields(N)$ on a smooth manifold $N$, an open $U \subseteq N$, a \textbf{Lax representation for $(X, U)$} is a smooth map $(L, M) : N \to \gl(n) \times \gl(n)$ such that
	\begin{eqalign}
		L_*X(L(x)) = [L(x), M(x)]
	\end{eqalign}
	or, equivalently,
	\begin{eqalign}
		\der{L}{t} = [L,M].
	\end{eqalign}
\end{definition}

It mimics the evolution of a quantum operator in the Heisenberg formalism.

\begin{proposition}
	The eigenvalues $\lambda_1(x), \ldots, \lambda_n(x)$ of the Lax matrix $L$ are integrals of motion of the system.
\end{proposition}
\begin{proof}
	Let $t_k = \trace L^k$, then eigenvalues of $L$ are roots of its characteristic polynomial:
	\begin{eqalign}
		\det(L- \lambda I) = (-1)^n(\lambda^n + c_1 \lambda^{n-1} + \ldots + c_n).
	\end{eqalign}
	Its coefficients can be written in terms of the trace through \textbf{Newton's formula}:
	\begin{eqalign}
		c_m = - \frac{t_m}m + \frac1{2!} \sum_{i+j = m} \frac{t_it_j}{ij} - \frac1{3!} \sum_{i+j +k = m} \frac{t_it_jt_k}{ijk} + \ldots + (-1)^m \frac{t_1^m}{m!}.
	\end{eqalign}
	Now, using the cyclic invariance of the trace to tackle the derivative, we obtain:
	\begin{eqalign}
		\der{}{t} \trace L^k &= k\trace ([L,M] L^{k-1})\\
			&= k \trace (LML^{k-1} - ML^k)\\
			&= 0.
	\end{eqalign}
	Then, as $c_1, \ldots, c_n$ depend only on the traces, which we've just shown to be constant of motions, the eigenvalues are constant of motions as well.
\end{proof}

\begin{theorem}
	Let $(L, M)$ be a Lax representation for a vector field on some smooth manifold $N$. Let $G: N \to \GL(n)$ be a smooth map. Then
	\begin{eqalign}
		L' = GLG^{-1},\quad M'=GMG^{-1}- \der{G}{t}G',
	\end{eqalign}
	where $t$ is the time of the Lax equation, is another Lax representation.
\end{theorem}
\begin{remark}
	The transformation is in the same spirit of the gauge transformation of a fiber bundle connection!
\end{remark}
\begin{proof}
	Using the formula $\der{G^{-1}}t = -G^{-1} \der{G}t G^{-1}$, we get
	\begin{eqalign}
		\der{L'}{t} &= \der{}{t}(GLG^{-1})\\[1ex]
			&= \der{G}{t}LG^{-1} +G[L,M]G^{-1} - GLG^{-1}\der{G}{t}G^{-1}\\[1ex]
			&= \der{G}t \textcolor{blue}{G^{-1}G}LG^{-1} + [GLG^{-1}, GMG^{-1}] - GLG^{-1}\der{G}{t}G^{-1}\\[1ex]
			&= \left[\der{G}tG^{-1}, L' \right] + [L', GMG^{-1}]\\[1ex]
			&= [L', M'].
	\end{eqalign}
\end{proof}
\begin{corollary}
	Since $L'$ is conjugate to $L$, hence they have the same eigenvalues, the Lax representation obtained in this way yields the same integrals of motion.
\end{corollary}

\begin{example}[{Classical finite Toda lattice, from \cite{oevel1989r}}]
\label{ex:toda_lattice}
	Take $\lalg = \gl(n)$ as before and split it into $\lalg_+ \dir \lalg_-$, where $\lalg_+$ is the space of lower triangular matrices and $\lalg_- = \so(n)$ the space of skew-symmetric ones. We will use the duality given by the trace to identify $\lalg$ with $\lalg^*$. Then
	\begin{eqalign}
		\lalg_+^* = \lalg_-^\perp = \{\text{symmetric matrices}\},
	\end{eqalign}
	and
	\begin{eqalign}
		\lalg_-^* = \lalg_+^\perp = \{\text{strictly lower triangular matrices}\}.
	\end{eqalign}
	Consider the projection given by
	\begin{eqalign}
		\pr_+(L) &= \underline\ell(L) + \overline{u}(L)^T + d(L),\\
		\pr_-(L) &= \overline{u}(L) - \overline{u}(L)^T,
	\end{eqalign}
	where $\underline{\ell}$ extracts the strictly lower triangular part, $\overline{u}$ the strictly upper triangular part and $d$ the diagonal. Likewise, we define projection operators on the dual algebra:
	\begin{eqalign}
		\pr_+^*(L) &= d(L) + \overline{u}(L) + \overline{u}(L)^T,\\
		\pr_-^*(L) &= \underline\ell(L)-\overline{u}(L)^T.
	\end{eqalign}
	Then let
	\begin{eqalign}
		R(L) &= \pr_+(L) - \pr_-(L) = \underline\ell(L) + 2 \overline{u}(L)^T + d(L) - \overline u(L)\\
		R^*(L) &= \pr_+^*(L)-\pr_-^*(L) = -\underline\ell(L) + 2\overline u(L)^T + d(L) + \overline u(L).
	\end{eqalign}
	We will build a hierarchy of commuting Hamiltonian equations on the space $\lalg$.
	Now, using Equation~\ref{eq:evolution_in_an_R_system} we can put a Poisson structure on $\lalg$:
	\begin{eqalign}
		\Pi^\sharp_R(A)\vert_L = [L,RA] + R^*[L,A].
	\end{eqalign}
	We could now get the integrals of motion from the traces, but that approach would be uninformative for the purpose of finding the system corresponding to the Toda lattice. We take another route. Let
	\begin{eqalign}
		S = \{ b+aT_- + T_-a\} \incat{LieAlg}\subseteq \lalg
	\end{eqalign}
	where
	\begin{eqalign}
		a = \begin{pmatrix}
			a_1 & & & &\\
			& a_2 & & &\\
			& & \ddots & &\\
			& & & a_{n-1} &\\
			& & & & 0
		\end{pmatrix},& \quad b = \begin{pmatrix}
			b_1 & & & &\\
			& b_2 & & &\\
			& & \ddots & &\\
			& & & b_{n-1} &\\
			& & & & b_n
		\end{pmatrix}\\[2ex]
		T_+ = \begin{pmatrix}
			0 & 1 & & &\\
			& 0 & 1 & &\\
			& & \ddots & &\\
			& & & 0 & 1\\
			& & & & 0
		\end{pmatrix},& \quad
		T_-  = \begin{pmatrix}
			0 & & & &\\
			1& 0 & & &\\
			& & \ddots & &\\
			& & 1& 0 &\\
			& & & 1& 0
		\end{pmatrix}.
	\end{eqalign}
	One could prove that, for any $L \in S$ and $A \in \lalg$, $\Pi^\sharp_R(A)\vert_L \in S$, which means $\Pi^\sharp_R(A)$ is tangent to $S$ if $L \in S$. This means $\im(\Pi_R(L)) \subseteq TS$, hence by Theorem~\ref{eq:poisson_submanifold_condition} there is a unique Poisson submanifold structure on $S$, given by the restriction of $\Pi_R$ to $S$. The function $c_k = \frac1k \trace L^k$ is Casimir for the Poisson structure of the dual algebra, and
	\begin{eqalign}
		\der{L}{t_k} = [L, R\nabla c_k]\quad \text{and} \quad \{c_i, c_j\}_R=0.
	\end{eqalign}
	For instance, take $k=2$.
	\begin{eqalign}
		\der{L}{t_2} = [L, R\nabla c_2] = [L, RL] \iff \begin{dcases}
			\dot{b}_i = 4(a_i^2 - a_{i-1^2})\\
			\dot{a}_i = 2a_i(b_{i+1} - b_i)
		\end{dcases}
	\end{eqalign}
	These are \textbf{Toda equations} and describe a finite line of particles interacting (exponentially) with their neighbours. This is a good example of a system which is not integrable at first sight, but where its abstract study brings out the $n$ integral of motions given by the Casimir functions we found, so we can completely integrate it.
\end{example}

\chapter{Bihamiltonian structures}
\section{Bihamiltonian structures}
We can think of the space of Poisson structures as a manifold, the submanifold of the manifold of bivectors defined by the quadratic equation \eqref{eq:jacobi_id_for_pi_tensor}. It is not a vector space \emph{per se}, but since it lives inside $\fields^2(M)$, which \emph{is} a vector space, can contain subspaces.

\begin{definition}
	A \textbf{bihamiltonian structure} on a smooth manifold $M$ is a $2$-dimensional linear subspace of the space of Poisson structures on $M$.
\end{definition}

An ordered basis $(\Pi_0, \Pi_1)$ of such a space is called a \textbf{pair of compatible Poisson tensors}. Since this means any linear combination of them is again a Poisson tensor, we've already seen we must have
\begin{eqalign}
	[\Pi_0, \Pi_1] = 0.
\end{eqalign}

Let us denote $\{-,-\}_i$ the Poisson bracket associated to the Poisson tensor $\Pi_i$.

\begin{theorem}[Magri]
\label{th:magri}
	Let $M$ be a smooth manifold equipped with two different Poisson structures, $\Pi_0$ and $\Pi_1$. Consider a sequence of functions $\seq{h}{n} \subseteq \Cinfty(M)$ satisfying the following ``Hamiltonian recursion'':
	\begin{eqalign}
		\{-,h_{p+1}\}_0 = \{-,h_p\}_1, \quad \forall p \in \N.
	\end{eqalign}
	Then $\{h_p,h_q\}_0 = \{h_p,h_q\}_1 = 0$ for all $p,q \in \N$.
\end{theorem}
\begin{remark}
	The relation is not really a recursion, since to really write $h_{p+1}$ in terms of $h_p$ one has to invert $\Pi_0^\sharp$ and then ``integrate'' which are both operations not possible in general (as $\Pi_0$ might be singular).
\end{remark}
\begin{proof}
	Suppose $q-p=2m$, for $m \neq 0$. Then, by using recursion and skew-symmetry:
	\begin{eqalign}
		\{h_p, h_q\}_0 &= \{h_p, h_{q-1}\}_1\\
		&= -\{h_{q-1}, h_p\}_1\\
		&= -\{h_{q-1}, h_{p+1}\}_0\\
		&= \{h_{p+1}, h_{q-1}\}_0
	\end{eqalign}
	We managed to dimish the difference of the indices of $2$, so that by repeating this $m$ times we'd arrive to $\{h_{p+m}, h_{q-m}\}_0 =0$. Likewise, if $q-p = 2m+1$ then we can arrive at
	\begin{eqalign}
		\{h_p, h_q\}_0 = \ldots = \{h_{p+m}, h_{q-m}\}_0 = \{h_{p+m}, h_{q-m-1}\}_1 = 0.
	\end{eqalign}
	Hence all the functions are in involution for the $0$-brackets, and by the recursion relation, it is a trivial exercise to check they are in involution for the $1$-bracket too.
\end{proof}

Notice \textbf{we actually didn't use the compatibility of $\Pi_0$ and $\Pi_1$ to get this result}. Indeed, it is not necessary. However a bihamiltonian structure gives us a canonical way to produce a sequence of functions in recursion in two particular cases:

\begin{enumerate}
	\item when the rank of any $\Pi \in \Span_\R \{\Pi_0, \Pi_1\}$ is constant (and non-maximal), or
	\item when one of the Poisson structures is non-degenerate, hence we have at our disposal a symplectic structure.
\end{enumerate}

Let's start with the first one.

\subsection{The Hamiltonian recursion in the constant rank case}
\begin{definition}
	A marked line $\Pi_0 + \varepsilon \Pi_1$ in a bihamiltonian structure $\{\Pi_0, \Pi_1\}$ is called a \textbf{Poisson pencil}.
\end{definition}

\begin{lemma}
\label{lemma:comp_poisson_of_const_rank_same_cas}
	Let $\Pi_\varepsilon = \Pi_0 + \varepsilon \Pi_1$ be a Poisson pencil of constant rank for small $\varepsilon$ and $k = \cork(\Pi_0 + \varepsilon\Pi_1) = \cork(\Pi_0)$. Then if $c_1, \ldots, c_k \in \Cas(M, \Pi_0)$, then
	\begin{eqalign}
		\{c_i,c_j\}_1 = 0, \quad \forall i,j \leq k.
	\end{eqalign}
\end{lemma}
\begin{remark}
	This is remindful of the alike theorem for Lax representations (Corollary~\ref{cor:cas_are_inherited}).
\end{remark}
\begin{proof}
	Let $2m = \rk(\Pi_0)$, so that $2m+k=\dim M$. Let us choose Darboux--Weinstein coordinates for $\Pi_0$ centered at $p \in M$ ($c^{ij}(p) = 0$ in the notation of Theorem~\ref{th:darboux_weinstein}). Then
	\begin{eqalign}
		\Pi_0^{ab}\vert_p = \begin{pmatrix}
			0 & I & 0\\
			-I & 0 & 0\\
			0 & 0 & 0
		\end{pmatrix}.
	\end{eqalign}
	Hence
	\begin{eqalign}
		(\Pi_0 + \varepsilon \Pi_1)^{ab} = \begin{pmatrix}
			O(\varepsilon) & I + O(\varepsilon) & O(\varepsilon)\\
			-I + O(\varepsilon) & O(\varepsilon) & O(\varepsilon)\\
			O(\varepsilon)& O(\varepsilon) & O(\varepsilon)
		\end{pmatrix}.
	\end{eqalign}
	The fact that $\rk(\Pi_\varepsilon) = \rk(\Pi_0) = 2m$ implies the determinant of any minor of order $2m+1$ vanishes. In particular, consider the minor $M_{ij}$ we get from adjoining the $i$-th row and the $j$-th column ($2m < i,j \leq 2m+k$) to the upper left minor of size $2m$. Developing the determinant of such a minor with respect to the adjoined row, we obtain\footnotemark
	\begin{eqalign}
		0 = \det M_{ij}(\varepsilon) = \underbrace{(-1)^{4m+2} (\Pi_0^{ij} + \varepsilon \Pi_1^{ij})}_{\text{rightmost element}} + \underbrace{O(\varepsilon)}_{\text{others}} = \varepsilon \Pi_1^{ij} + O(\varepsilon^2), \quad \forall i,j.
	\end{eqalign}
	Since $\det M_{ij}$ is a polynomial in $\varepsilon$ which vanishes on a whole neighbourood of $\varepsilon = 0$, thus it must be the zero polynomial, implying $\Pi_1^{ij} = 0$ for $2m < i,j \leq 2m+k$. Now recall that $\Pi^{ij} = \{x^i, x^j\}$, so this result about the components of $\Pi_1$ translates to the thesis, since the last $k$ coordinates of a Darboux--Weinstein system are (a basis for) Casimirs.
	\footnotetext{An appreciable digression should be made about how did we obtain the stated equalities. Eventually, the employed results are the consequence of a careful and attentive application of the definition of determinant to the peculiar structure the involved matrices have, hence a challenging, if pedant, exercise. Explicitly, we are using the fact that:
	\begin{eqalign}
		\left| \begin{matrix}
			O(\varepsilon) & I + O(\varepsilon)\\
			-I + O(\varepsilon) & O(\varepsilon)
		\end{matrix} \right| = 1 + O(\varepsilon),
	\end{eqalign}
	while the same matrix with any line replaced by one whose entries are $O(\varepsilon)$ has determinant $O(\varepsilon)$. Applying Laplace's formula to the stated row leads to the expression of $\det M_{ij}$ we used.}
\end{proof}

\begin{lemma}
\label{lemma:poisson_cohomology_is_loc_trivial}
	Let $\Pi$ be a Poisson structure of constant rank $2m$ on a $(2m+k)$-dimensional smooth manifold $M$. Locally, in a sufficiently small open ball (in the topological sense, i.e. homeomorphic to a ball of suitable dimension) $U \subseteq M$:
	\begin{enumerate}
		\item if $\overline X \in H^1_\Pi(U)$, then $\overline X = 0$ (i.e. the Poisson vector field $X$ is Hamiltonian) if and only if $X = \Pi^\sharp \eta$ for some $\eta \in \Omega^1$ (hence not necessarily closed),
		\item if $\overline\Delta \in H^2_\Pi(U)$, then $\overline\Delta =0$ (i.e. the first-order deformation given by $\Delta$ is trivial) if and only if is zero on the Casimirs.
	\end{enumerate}
\end{lemma}
\begin{proof}
	\leavevmode
	\begin{enumerate}
		\item If $\overline X =0$, then $X = \Pi^\sharp(df)$ for some $f \in \Cinfty(M)$, then of course $X \in \im \Pi^\sharp$. Conversely, suppose $X \in \im \Pi^\sharp$. Let's start by putting Darboux--Weinstein coordinates $(x^i, \xi^i, c^j)$ on $U$ of $M$. Use the Casimir coordinates to foliate the ball in symplectic leaves. We'll denote with $U_c$ the symplectic leaf where Casimirs have a fixed value $c \in \R^k$. Then on any of these, $\Pi\vert_{U_c} = \partial_{x^i} \wedge \partial_{\xi^i}$. Consider now its transpose, which is simply Darboux $2$-form $\omega_c = dx^i \wedge d\xi^i$. Extending $\omega_c$ on the whole ball $U$, we would get a closed form, even if not a symplectic one. Now, since $[\Pi, X] = 0$ then $\Lie{X}\omega_c$ as well, thus:
		\begin{eqalign}
			\Lie{X}\omega_c = d\ipr{X}\omega_c + \ipr{X}d\omega_c = d\ipr{X}\omega_c = 0.
		\end{eqalign}
		Then, locally on $U_c$, $\iota_X \omega_c = df_c$ where $f_c \in \Cinfty(U_c)$. We can write then
		\begin{eqalign}
			\iota_X \omega = df + \text{transverse\footnotemark\ part} \in \Omega^1(U),
		\end{eqalign}
		\footnotetext{Here and in the following ``transverse'' means along the $k$ directions of degeneracy of the Poisson structure.}
		where $f(x,\xi,c) = f_c(x,\xi) \in \Cinfty(U)$. Remember, now, that $\iota_-\omega$ is the inverse of $\omega^{-1} = \Pi\vert_{U_c}^\sharp$. Thus, leafwise
		\begin{eqalign}
			X\vert_{U_c} &= \Pi\vert_{U_c}^\sharp(\iota_X\omega)\\
			&= \Pi^\sharp\vert_{U_c}(df\vert_{U_c} +\text{transverse part})\\
			&= \Pi^\sharp\vert_{U_c}(df_c) + \underbrace{\Pi^\sharp\vert_{U_c}(\text{transverse part})}_{\text{$=0$ by def.}}
		\end{eqalign}
		 Thus, since the symplectic foliation of $U$ partitions $U$, we get $\Pi^\sharp(df) = [\Pi, f] = X$.
		\item If $\overline \Delta = 0$, then $\Delta = \mathcal{L}_X\Pi= [X,\Pi]$ for $X \in \fields(U)$, so that for $c_1,c_2 \in \Cas(U)$
		\begin{eqalign}
			\Delta(dc_1, dc_2) = \left(\mathcal{L}_X\Pi\right)(dc_1,dc_2),
		\end{eqalign}
		and to compute it we recall that
		\begin{eqalign}
		 0=\Lie{X}(\{c_1,c_2\})&=\Lie{X}(\Pi(dc_1,dc_2))=	\\
				       &=(\Lie{X})(dc_1,dc_2)+\Pi(\Lie{X}dc_1,dc_2)+\Pi,(dc_1,\Lie{X}dc_2),
		\end{eqalign}
		so that, since $\Lie{X}df=d(X(f))$ for all $f\in\Cinfty(M)$,
		\begin{equation}
		 \Delta(dc_1,dc_2)=-\{X(c_1),c_2\}-\{c_1,X(c_2)\}=0,
		\end{equation}
		as stated.

		Conversely, choose Darboux--Weinstein coordinates $x^i = (q^j, p^h, c^\ell)$. Consider the $k$ vectors given by the components of $\Delta$ in the transverse directions:
		\begin{eqalign}
			X_a = \Delta^{i\,\,2m+a} \pder{}{x^i}, \quad 1 \leq a \leq k.
		\end{eqalign}
		Since $\Delta$ is zero on Casimirs, this means $X_a^{i+2m} = 0$ for $i=1,\ldots,k$, therefore $X_a\in \im(\Pi^\sharp)$ since it is
		tangent to the symplectic leaves.

		Now, let us compute explicitly the components of $[\Pi, \Delta]$ and of $[\Pi, X_a]$.
		As for $[\Pi, \Delta]$, one finds by direct computation (using the S-N brackets definition and properties)
		\begin{eqalign}
		 [\Pi,\Delta]^{ijh}=&-(\Delta^{hl}\partial_h\Pi^{ij}+\Delta^{ih}\partial_h\Pi^{jl})	\\
				    &-(\Pi^{hi}\partial_h\Delta^{jl}+\Pi^{hj}\partial_h\Delta^{li}),
		\end{eqalign}
		and since $\Pi^{ij}$ are constant in D-W coordinates
		\begin{equation}
		 [\Pi,\Delta]^{ij\,2m+a}=-(\Pi^{hi}\partial_h\Delta^{j\,2m+a}+\Pi^{hj}\partial_h\Delta^{2m+a\,i}).
		\end{equation}
		As for $[\Pi, X_a]$, by direct computation one gets
		\begin{equation}
		 [\Pi,X_a]^{ij}=-(\Pi^{hi}\partial_{h}\Delta^{j\,2m+a}+\Pi^{hj}\partial_{h}\Delta^{2m+a\,i}),
		\end{equation}
		which proves that
		\begin{equation}
		 [\Pi,X_a]^{ij}=[\Pi,\Delta]^{ija},\quad  1 \leq a \leq k.
		\end{equation}
		Now, by hypothesis $[\Pi,\Delta]=0$, so we find
		\begin{equation}
		 \Lie{X_a}\Pi=0,
		\end{equation}
		that is $X_a$ is a Poisson vector field for all $a=1,\ldots,k$: $\overline{X_a}\in H^1_\Pi(U)$.

		Therefore, we just built $k$ vector fields $X_a$ such that
		\begin{enumerate}
		 \item $\overline{X_a}\in H^1_\Pi(U)$;
		 \item $X_a\in\im(\Pi)$,
		\end{enumerate}
		so by the previous point, $X_a = [\Pi, f_a]$ for some $f_a \in \Cinfty(U)$.
		In local coordinates this reads $\Delta^{i\,a+2m} = 2\Pi^{ij}\partial_j f_a$ ($1 \leq a \leq k$),
		which implies the constraint on the $f_a$
		\begin{equation}
		 \Pi^{2m+a\,j}\partial_j f_b=0.
		\end{equation}
		Let us now change representative for this cohomology class, taking $\Delta^\prime=\Delta-[\Pi,Z]$ as the new one,
		where we defined \textit{ad hoc}
		\begin{equation}
		 Z=\sum_{a=1}^k Z^{2m+a}\pder{}{c^a}=\sum_{a=1}^k 2f_a\pder{}{c^a}.
		\end{equation}

		Let us show why this is convenient.
		By direct computation one finds
		\begin{equation}
		 [\Pi,Z]^{i\,2m+a}=\Delta^{i\,2m+a},
		\end{equation}
		which implies that now the new representative is such that
		\begin{equation}
		 \Delta^{\prime\,i\,2m+a}=\Delta^{\prime\,2m+a\,i}=0,
		\end{equation}
		while it keeps holding, just like for $\Delta$,
		\begin{equation}
		 \Delta^{\prime\,2ma+a\,2m+b}=0.
		\end{equation}
		This means that $\Delta^\prime$ only has non-zero components along $\pder{}{q^i}$ and $\pder{}{p^i}$ directions,
		that is $\Delta^{\prime\sharp}$ can be really ``restricted'' to the symplectic leaves $U_c$, for all $c\in U$:
		\begin{equation}
		 \Delta^\prime_c:\Omega^1(U_c)\longrightarrow\fields(U_c).
		\end{equation}

		This allows us to lower the indices of $\Delta$ and define, said $\omega=dq^i\wedge dp_i$,
		\begin{equation}
		 \delta=\omega_{\bullet k}\Delta^{kl}\omega_{l\bullet}\in\Omega^2(U),
		\end{equation}
		which means $\delta=\omega\circ\Delta\circ\omega$, and correspondingly we have the leaf-restricted version
		\begin{equation}
		 \delta_c=\omega_c\circ\Delta_c\circ\omega_c	\quad	\forall c\in U.
		\end{equation}
		Now, $\Pi_\epsilon=\Pi+\epsilon\Delta$ is Poisson at first order in $\epsilon$ if and only if $[\Pi, \Delta]=0$,
		and this is true by hypothesis.
		Moreover, we know $\Pi_c$ is symplectic and $\Delta_c$ is well defined, therefore $\Pi_\epsilon\vert_c=\Pi_c+\epsilon\Delta_c$
		is Poisson if and only if $[\Pi\vert_c,\Delta_c]=0$, which is true by hypothesis, and since
		\begin{equation}
		 \Pi_\epsilon\vert_c^{-1}=\omega_\epsilon\vert_c=\omega_c-\epsilon\omega_{\bullet h}\Delta^{hl}\omega_{l\bullet}+\mathcal{O}(\epsilon^2)
		\end{equation}
		then $\omega_\epsilon\vert_c$ is symplectic if and only if $d\omega_\epsilon\vert_c=0$, that is iff $d\delta_c=0$,
		which shows that $\delta_c$ is closed on the symplectic leaves $U_c$.

		Therefore, analogously to what we did in point 1. of this proof, by PoincarÃ¨ lemma $d\delta_c$ is locally
		exact:
		\begin{equation}
		 \delta_c=d\phi_c	\quad 	\exists\phi_c\in\Omega^1(U_c)\quad\forall c\in U
		\end{equation}
		so that, going back outside the leaves, $\delta=d\phi+\tilde{\delta}$ for some $\tilde{\delta}\in\Omega^2(U)$,
		where $\phi(q,p,c)=\phi_c(q,p)$ and $\tilde{\delta}$ contains at least one $dc^a$ in each summand.
		Now, to recover $\Delta^\prime$ we compose the identity $\delta=d\phi+\tilde{\delta}$ with $\Pi$ on both
		sides:
		\begin{equation}
		 \underbrace{\Pi\delta\Pi}_{\Delta^\prime}=\Pi d\phi\Pi+\underbrace{\Pi\tilde{\delta}\Pi}_{0}
		\end{equation}
		so $\Delta^\prime=\Pi d\phi\Pi$, and by direct computations one finds that
		\begin{equation}
		 \Pi d\phi \Pi=-[\Pi,\Pi(\phi)]
		\end{equation}
		that is $\Delta^\prime=-[\Pi,\Pi(\phi)]$ (where we mean $\Pi(\phi)=\Pi^{ij}\phi_j\partial_i\in\fields(M)$).
		This proves that $\bar{\Delta^\prime}=0$, as we wanted.
	\end{enumerate}
\end{proof}

\begin{corollary}
	Let $\Pi_0 + \varepsilon \Pi_1$ be a Poisson pencil of constant rank for small $\varepsilon$ and on some ball $U \subseteq M$. Then
	\begin{eqalign}
		\overline \Pi_1 = 0 \in H^2_{\Pi_0}(U).
	\end{eqalign}
\end{corollary}
\begin{proof}
	From Lemma~\ref{lemma:comp_poisson_of_const_rank_same_cas} we know $\Pi_1$ vanishes on the Casimirs of $\Pi_0$, hence the corollary follows from the second claim of Lemma~\ref{lemma:poisson_cohomology_is_loc_trivial}.
\end{proof}

The meaning of the last result is that if $(\Pi_0, \Pi_1)$ forms a Poisson pencil of constant rank, then we can locally reabsorb any deformation of $\Pi_0$ by $\Pi_1$ with a coordinate change.

\begin{theorem}
	Let $\Pi_\varepsilon = \Pi_0 - \varepsilon \Pi_1$ be a Poisson pencil of constant rank for small $\varepsilon$ on a ball $U$ on the manifold $M$. Let $c^1(\varepsilon), \ldots, c^k(\varepsilon)$ be $k = \cork(\Pi_0) = \cork(\Pi_0-\varepsilon \Pi_1)$ independent Casimirs for $\Pi_\varepsilon$ and let
	\begin{eqalign}
	\label{eq:casimir_taylor_exp}
		c^i(\varepsilon) = c^i_{-1} + c^i_0\varepsilon + c_1^i\varepsilon^2 + \ldots
	\end{eqalign}
	be their Taylor expansion in $\varepsilon$ around $\varepsilon = 0$ (it's a power series of $\varepsilon$). Then the sequences $\seq{c^i}{p}$ are in Hamiltonian recursion, and moreover they \textbf{all} commute with each other with respect to both brackets:
	\begin{eqalign}
		\{c^i_p, c^j_q\}_0 = \{c^i_p, c^j_q\}_1 = 0
	\end{eqalign}
\end{theorem}
\begin{proof}
	Since $c^i(\varepsilon)$ is a Casimir of $\Pi_\varepsilon$,
	\begin{eqalign}
		0 &= \{-,c^i(\varepsilon)\}_\varepsilon\\
		&= \{-, c^i(\varepsilon)\}_0 - \varepsilon \{-,c^i(\varepsilon)\}_1\\
		&= \left( \sum_{p=-1}^{\infty} \{-,c^i_p(\varepsilon)\}_0 \varepsilon^{p+1} \right) + \varepsilon\left( \sum_{p=-1}^{\infty} \{-,c^i_p(\varepsilon)\}_1 \varepsilon^{p+1} \right)\\
		&= \sum_{p=-1}^{\infty} (\{-,c^i_p\}_0 - \{-,c^i_{p+1}\}_1)\varepsilon^{p+1}
	\end{eqalign}
	where we set $c^i_{-2} = 0$. Then the fact all the coefficients of the above power series vanish correspond to the wanted recursion relation. Theorem~\ref{th:magri} takes care of the commuting relations among each of the $k$ sequences $\seq{c^i}{p}$, so we just need to prove the functions commute also when in different sequences. To do this, we turn the trick we used for Magri's Theorem on its head: we spread the functions apart until one of them hits $-1$, at which point we can use the fact $c^i_{-1}$ is Casimir at $\varepsilon =0$ (because the rest of the terms of \eqref{eq:casimir_taylor_exp} vanish):
	\begin{eqalign}
		\{c^i_p, c^j_q\}_0 &= \{c^i_p, c^j_{q-1}\}_1\\
		&= -\{c^j_{q-1}, c^i_p\}_1\\
		&= -\{c^j_{q-1}, c^i_{p+1}\}_0\\
		&= \{c^i_{p+1}, c^j_{q-1}\}_0\\
		&= \ldots\\
		&= \{c^i_{p+q+1}, c^i_{-1}\}_0 = 0
	\end{eqalign}
\end{proof}

Hence the ``canonical way'' to get an Hamiltonian recursion out of a bihamiltonian structure of constant rank is to find the Taylor expansion of the Casimirs. \textbf{How do we find it?}

\begin{construction}
	One strategy goes like this. We have shown that if $\Pi_0-\varepsilon\Pi_1$ is a Poisson pencil of constant rank, then $\overline \Pi_1 = 0 \in H_{\Pi_0}^2(U)$. This means $\Pi_1 = \Lie{Z}\Pi_0$ for some $Z \in \fields^1(U)$. Let us make the additional assumption that $\Lie{Z}^2\Pi_0 = 0$, i.e. the Poisson pencil is \textbf{exact}.

	On a fixed coordinate patch, one can rectify $Z = \partial_1$ so that $\Pi_0^{ij}$ will depend linearly on $x^1$ (since the second derivative vanishes), while $\Pi_1^{ij}$ will be independent of it (since $\Lie{\partial_1} \Pi_1 = \Lie{\partial_1}\Lie{\partial_1}\Pi_0 = 0$). This means that, if $\mathsf{shift}^1_\varepsilon$ is the change of coordinates sending $x_1$ to $x_1 - \varepsilon$, then
	\begin{eqalign}
		\mathsf{shift}^1_\varepsilon(\Pi_0)^{ij} = \Pi_0^{ij} - \varepsilon \Pi_1^{ij} = \Pi_\varepsilon^{ij}.
	\end{eqalign}
	This shows that the Casimirs of $\Pi_\varepsilon$ are $c^i(\varepsilon) = \mathsf{shift}^1_\varepsilon(c^i_{-1})$, hence we have a simple way to get the desired functions from the Casimirs of $\Pi_0$:
	\begin{eqalign}
		c^i(\varepsilon) = \exp(\varepsilon Z)c^i_{-1} = c^i_{-1} + \varepsilon Z(c^i_{-1}) + \frac{\varepsilon^2}2 Z(Z(c^i_{-1})) + \ldots
	\end{eqalign}
\end{construction}

\begin{example}[Toda lattice]
	Remember Toda's equations from Example~\ref{ex:toda_lattice} (we rescaled them by a factor to get nicer numbers later on):
	\begin{eqalign}
		\begin{cases}
			\dot{a}_i = a_i (b_{i+1} - b_i)\\
			\dot{b}_i = 2(a_i^2 - a_{i-1}^2)
		\end{cases}
	\end{eqalign}
	Geometrically, we think of $a_1, \ldots, a_{n-1}$ and $b_1, \ldots, b_n$ as coordinates on a manifold. We equip it with a Poisson structure by setting
	\begin{eqalign}
		\{a_i, b_i\}_1 = -a_i, \quad \{a_i, b_{i+1}\}_1 = a_i
	\end{eqalign}
	and zero in every other case.

	Usually, one gets the $a_i$s and the $b_i$s from another set of (physical) coordinates $(p_i, q_i)$ by the following change of variables:
	\begin{eqalign}
		\begin{dcases}
			a_i = \frac12 \e^{\frac12 (q_i - q_{i+1})}\\
			b_i = -\frac12 p_i
		\end{dcases}
	\end{eqalign}
	With respect to those coordinates, the bracket is just $\{q_i, p_j\}_1 = \delta_{ij}$. The Hamiltonian of the system is
	\begin{eqalign}
		H = \frac12 (b_1^2 + \ldots + b_n^2) + a_1^2 + \ldots + a_{n-1}^2.
	\end{eqalign}
	The interpretation for this Hamiltonian is that the first term is a kinetic energy term while the second is a potential energy term for an exponential potential which is defined among neighbouring particles. The system has also a Lax representation as
	\begin{eqalign}
		L &= \begin{pmatrix}
			b_1 & a_1 & & & 0\\
			a_1 & & \ddots & & \\
			& & \ddots & & \\
			& & \ddots & & a_{n-1}\\
			0 & & & a_{n-1} & b_{n-1}
		\end{pmatrix},\\[2ex]
		B &= \begin{pmatrix}
			0 & a_1 & & & 0\\
			-a_1 & & \ddots & & \\
			& & \ddots & & \\
			& & \ddots & & a_{n-1}\\
			0 & & & -a_{n-1} & 0
		\end{pmatrix} = \pr_- L = \overline{u}(L) - \overline(u)L^T
	\end{eqalign}
	In lieu of $B=RL$ we have $B=\pr_-L$, but it is the same thing as
	\begin{eqalign}
		R = \pr_+ - \pr_- = \pr_+ \pr_- - 2\pr_- = \id - 2\pr_-.
	\end{eqalign}
	The symmetries of the system are given by the trace of $L$, $b_1 + \ldots + b_n$. It is a Casimir function since
	\begin{eqalign}
		\{\trace L, b_i\}_1 &= 0,\\
		\{\trace L, a_i\}_1 &= \{b_1, a_i\}_1 + \ldots + \{b_i, a_i\}_1 + \{b_{i+1}, a_i\}_1 + \ldots + \{b_n, a_i\}_1\\
		&= 0 + \ldots + 0 + \cancel{-a_i + a_i} + 0 + \ldots + 0 = 0.
	\end{eqalign}
	This, and the traces of higher powers of $L$, are the symmetries of the lattice (but only the first are Casimirs).

	We now give a second Hamiltonian structure to the system, by providing new Poisson brackets. The pivotal observation is that the bracket we just defined is independent from the $b_i$ coordinates, as we see from the definition (a $b_i$ coordinate never appears on the right hand side). So we guess (there are actually good theoretical reason for this) there might be a second compatible Poisson bracket linearly dependent on the $b_i$s, to which we could then apply the machinery we just derived for this case. So we start by adding a linear dependence on $b_i$s:
	\begin{eqalign}
		\{a_i, b_i\}_2 = -a_ib_i, \quad \{a_i, b_{i+1}\}_2 = a_ib_{i+1}
	\end{eqalign}
	and then we correct the rest of the terms in order to satisfy the Jacobi identity:
	\begin{eqalign}
		\{a_i, a_{i+1}\}_2 = \frac12 a_i a_{i+1}, \quad \{b_i,b_{i+1}\}_2 = 2a_i^2.
	\end{eqalign}
	So the Poisson pencil is exact (because $\Pi_1$ is independent of the $b_i$ and $\Pi_2$ depends only linearly on them), and
	\begin{eqalign}
		Z = \sum_{i=1}^n \partial_{b_i}.
	\end{eqalign}
	One can show $\det L$ is a Casimir for $\{-,-\}_2$, and we get $\mathsf{shift}^1_\varepsilon(\det L)= \det (L-\varepsilon I)$. This latter object is the characteristic polynomial of $L$ evaluated at $\varepsilon$, thus the coefficients of its Taylor expansion in $\varepsilon$ coincides with its coefficient as a polynomial, are exactly $n$ and given by the traces of successive powers of $L$.
\end{example}

The situation of this example is general: given an $R$-matrix for a Lie--Poisson structure, there's a canonical way to construct a second (and actually even a third) compatible quadratic Poisson structure. The spectral invariants we get from the Lax representation are then in Hamiltonian recursion for this pair of Poisson structures.

\subsection{The Hamiltonian recursion in the symplectic case}
In the case one of the Poisson is symplectic, we do not have enough Casimir functions\footnote{This is especially true for the constant rank case: in fact, under this assumption the non-degeneracy of one Poisson structure forces non-degeneracy in the other, so we really do not have any Casimir.} so we need a different approach.

\subsection{Nijenhuis structures}
For this section, we refer to \cite{magri1984geometrical}. In this seminal paper, Magri and Morosi set out the theory of Poisson--Nijenhuis geometry, which deals with ``compatible'' tensor structures of Poisson, Nijenhuis and symplectic type. The article obtains hierarchies of symmetries out of this especially nice situation, through the method of Hamiltonian recursions.

\begin{definition}
	The \textbf{Nijenhuis torsion} is the operator
	\begin{eqalign}
		T(N)(X,Y) = [NX, NY] - N([NX, Y] + [X,NY]) + N^2[X,Y], \quad \forall X,Y \in \fields(M),
	\end{eqalign}
	where $N \in \fields^1_1(M)$.
\end{definition}

\begin{definition}
	A tensor field $N \in \fields^1_1(M)$ is called \textbf{Nijenhuis} if it satisfies $T(N) = 0$.
\end{definition}

\begin{definition}
	A \textbf{Nijenhuis manifold} is a smooth manifold $M$ equipped with a Nijenhuis tensor $N$.
\end{definition}

However, the most interesting situation comes when a Nijenhuis structure coexists (nicely) with a symplectic or Poisson structure:

\begin{definition}
	A \textbf{symplectic--Nijenhuis manifold} $M$ is a symplectic manifold $(M, \omega)$ equipped with a Nijenhuis tensor $N$ such that
	\begin{eqalign}
	\label{eq:symp_nijenhuis_conditions}
		S(\omega, N) = 0, \quad \omega N - N^*\omega = 0.
	\end{eqalign}
	where $S$ is an operator defined as
	\begin{eqalign}
		S(\eta, Q)(X,Y) := \Lie{QY}(\eta)X - \Lie{QX}(\eta)Y + \eta Q[X,Y] + d\langle \eta Q Y,X \rangle, \quad X,Y \in \fields(M).
	\end{eqalign}
\end{definition}

The first condition is a compatibility, \emph{a fortiori} condition, which arises from computation regarding how Hamiltonian vector are preserved by the Nijenhuis tensor (it basically implies that the symmetries arising from Lemma~\ref{lemma:fund_fields_of_nijenhuis} can be Hamiltonian if we start with Hamiltonian fields). The second condition expresses antisymmetry for $\omega N$, where the spurious minus sign comes from the antisymmetry of $\omega$ itself. In the case $N=\Pi\omega$, then it is fullfilled and it's really an antisymmetry condition (since $\omega\Pi\omega$ is the composition of an odd number of antisymmetric tensors, thus antisymmetric itself).

\begin{definition}
	A \textbf{Poisson--Nijenhuis manifold} is a Poisson manifold $(M,\Pi)$ equipped with a Nijenhuis tensor $N$ such that
	\begin{eqalign}
	\label{eq:poisson_nijenhuis_conditions}
		R(\Pi,N) = 0, \quad N\Pi - \Pi N^* = 0
	\end{eqalign}
	where $R$ is an operator defined as
	\begin{eqalign}
		R(P,Q)(\alpha, X) := \Lie{P\alpha}(Q)X - P\Lie{X}(Q^* \alpha) + P\Lie{QX}\alpha, \quad \alpha \in \Omega^1(M), X \in \fields(M).
	\end{eqalign}
\end{definition}

The first intriguing geometric result about these structures is that any ``symplectic--Poisson'' manifold can be given the structure of both a symplectic--Nijenhuis manifold, by defining $N=\Pi\omega$, and that of a Poisson--Nijenhuis manifold, by setting $\omega = \Pi^{-1}N$ (actually, in the case that $\Pi$ is non-degenerate).

\begin{lemma}
\label{lemma:powers_of_comp_are_closed}
	Let $\Pi$ be a Poisson structure on $M$ and $\omega$ a compatible symplectic form. Then
	\begin{eqalign}
		d(\omega(\Pi \omega)^n) = 0, \quad \forall n \in \N.
	\end{eqalign}
\end{lemma}
\begin{proof}
	Since $\omega$ is compatible with $\Pi$, $(\omega^{-1}, \Pi)$ is a bihamiltonian structure. In particular, $\omega^{-1}-\varepsilon \Pi$ is Poisson and non-degenerate if $\varepsilon$ is sufficiently small, so that $(\omega^{-1}-\varepsilon \Pi)^{-1}$ is symplectic, and
	\begin{eqalign}
		(\omega^{-1}(1-\varepsilon \omega \Pi))^{-1} = \left(\sum_{n=0}^\infty (\varepsilon \omega \Pi)^n \right) \omega = \omega + \varepsilon \omega \Pi \omega + \varepsilon^2 \omega \Pi \omega \Pi \omega + \ldots.
	\end{eqalign}
	Because symplectic implies closed, and $d$ it's a linear operator, the above expression gives the thesis for every value of $n \in \N$.
\end{proof}

\begin{proposition}
	Let $\Pi$ be a Poisson tensor and $\omega$ a symplectic form on some manifold $M$, such that $d(\omega\Pi\omega) = 0$. Then $\Pi\omega$ is a Nijenhuis tensor.
\end{proposition}
\begin{proof}
	The proof rests on the following identity, whose lengthy proof can be found in \cite[Appendix A]{magri1984geometrical}: given $P \in \fields^2(M)$ and $\eta \in \Omega^2(M)$,
	\begin{eqalign}
		T(P\eta)(X,Y) = [P,P](\eta X, \eta Y) - PS(\eta,P\eta)(X,Y).
	\end{eqalign}
	Now, when $P = \Pi$ and $\eta = \omega$, we have $[\Pi, \Pi] = 0$ as $\Pi$ is Poisson, $d\omega = 0$ as $\omega$ is symplectic, and $d(\Pi\Omega) = 0$ by hypothesis, therefore all the terms of $T(\Pi\omega)$ vanish, as claimed.
\end{proof}

Indeed symplectic, Poisson and Nijenhuis structures dance around each other in an interesting way:

\begin{center}
	\begin{tabular}{c|c|c|l}
		\textbf{Symplectic} & \textbf{Poisson} & \textbf{Nijenhuis} & \textbf{given that}\\[1ex]
		\hline
		$\omega$ & $\Pi$ & $\Pi\omega$ & $d(\omega\Pi\omega) = 0$\\[1ex]
		$\omega$ & $N\omega^{-1}$ & $N$ & Conditions~\eqref{eq:symp_nijenhuis_conditions}\\
		$\Pi^{-1}N$ & $\Pi$ & $N$ & Conditions~\eqref{eq:poisson_nijenhuis_conditions} + $\Pi$ is non-degenerate.
	\end{tabular}
\end{center}

But even more interesting is the fact that symplectic-- and Poisson--Nijenhuis manifolds actually come in well-behaved hierarchies: starting from $(\omega, N)$ or $(\Pi, N)$ we can define new structures of the same type by iterated composition:
\begin{eqalign}
	P_{k+1} = N^k P, \quad \Omega_{k+1} = \Omega N^k.
\end{eqalign}
This in turn originates from the fact that Nijenhuis structures come in hierarchies, given again by iterated composition (so that when $(M,N)$ is Nijenhuis manifold, so is $(M, N^k)$ for any $k \in \N$).

% Let's start to put this machinery at the disposal of integrability theory. The first step is to develop a theory of ``Hamiltonian'' vector fields for Nijenhuis structures, in parallel with symplectic and Poisson manifolds.

% \begin{definition}
% 	Let $(M,N)$ be a Nijenhuis manifold, and let $N^*$ be the transpose\footnote{Which means $\langle NX, \alpha \rangle = \langle X, N^*\alpha \rangle$.} of $N$. A \textbf{fundamental form} for the Nijenhuis tensor is a closed form $\alpha \in \Omega^1(M)$ such that
% 	\begin{eqalign}
% 		dN^*\alpha = 0.
% 	\end{eqalign}
% \end{definition}
% \begin{definition}
% 	A \textbf{fundamental field} on a Poisson--Nijenhuis manifold $(M,N,\Pi)$ is the image of a fundamental form through the $\Pi$-sharp operator:
% 	\begin{eqalign}
% 		X = \Pi^\sharp(\alpha), \quad dN^*\alpha = 0, \quad d\alpha = 0.
% 	\end{eqalign}
% \end{definition}

% \begin{proposition}
% 	The fundamental fields of $(M,N,\Pi)$ are exactly those which preserve both the Poisson and the Nijenhuis structure.
% \end{proposition}
% \begin{proof}

% \end{proof}

\begin{lemma}
	When $N$ is a Nijenhuis tensor,
	\begin{eqalign}
	\label{eq:nijenhuis_prop}
		\Lie{NX}(N) = N\Lie{X}(N), \quad \forall X \in \fields(M).
	\end{eqalign}
\end{lemma}
\begin{proof}
	\begin{eqalign}
		T(N)(X,Y) &= [NX,NY] - N([X, NY] + [NX, Y]) + N^2[X,Y]\\
		&= (\Lie{NY}(NX) - N\Lie{NY}(X)) - N(\Lie{Y}(NX) - N\Lie{Y}(X))\\
		&= \Lie{NY}(N)X - N(\Lie{Y}(N)X).
	\end{eqalign}
	Thus when $N$ is Nijenhuis, the thesis follows.
\end{proof}

\begin{lemma}
\label{lemma:fund_fields_of_nijenhuis}
	Let $N$ be Nijenhuis and let $\{X_1, \ldots, X_n, \ldots\}$ be a system of vector fields in involution and preserving $N$ ($\Lie{X_i}N=0$ for any $n$). Then
	\begin{eqalign}
		[N^k X_i, N^h X_j] = 0,
	\end{eqalign}
	where exponents denote repeated application.
\end{lemma}
\begin{proof}
	We get the claim by repeated applications of the Leibniz rule, and in the last step using Equation~\ref{eq:nijenhuis_prop}:
	\begin{eqalign}
		[N^k X_i, N^h X_j] &= \Lie{N^kX_i}(N^h X_j)\\
			&= \Lie{N^k X_i}(N^h)X_j + N^h \Lie{N^k X_i}(X_j)\\
			&= \left(\sum_{n=0}^{h-1} N^n \Lie{N^k X_i}(N)N^{h-n-1} X_j\right) - N^h \Lie{X_j}(N^k X_i)\\
			&= \left(\sum_{n=0}^{h-1} N^n N^k \underbrace{\Lie{X_i}(N)}_0 N^{h-n-1} X_j\right) - N^h \underbrace{\Lie{X_j}(N^k)}_0X_i - N^{h+k}\underbrace{\Lie{X_j}{X_i}}_0\\
			&= 0.
	\end{eqalign}
\end{proof}

A peculiar fact about the hierarchy of Poisson tensors we get out of a Poisson--Nijenhuis structure is that
\begin{eqalign}
	[\Pi_i, \Pi_j] = 0, \quad \forall i,j;
\end{eqalign}
so Nijenhuis tensor become a rich source of bihamiltonian structures. Then Lemma~\ref{lemma:fund_fields_of_nijenhuis} tells us that when we find a system of commuting fields which preserve $N$, we get out a whole hierarchy of them. One can show that $X_i$ is Hamiltonian with respect to each $\Pi_j$, $j \leq i$, and that this fact characterizes completely integrable systems.

\subsection{The recursion}
\begin{theorem}
	The functions
	\begin{eqalign}
		h_{p+1} := \frac1{p+1} \trace N^{p+1},
	\end{eqalign}
	for positive $p$, satisfy the recursion
	\begin{eqalign}
		dh_{p+1} = N^* dh_p.
	\end{eqalign}
\end{theorem}
\begin{remark}
	Notice that, when $N=\Pi\omega$, $N^* = \omega \Pi$ by antisymmetry. This means the recursion is
	\begin{eqalign}
		dh_{p+1} &= \omega\Pi dh_p\\
		\omega^{-1}(dh_{p+1}) &= \Pi(dh_p)\\
		\{-,h_{p+1}\}_{\omega^{-1}} &= \{-,h_p\}_\Pi
	\end{eqalign}
	that is, the Hamiltonian recursion of Magri's Theorem! However, the result is completely general since we do not assume $N$ to be in a particular form, indeed, we do not even assume the manifold to be Poisson or symplectic.
\end{remark}
\begin{proof}
	Recall contractions commute with Lie derivatives, then we compute
	\begin{eqalign}
		\langle dh_{p+1}, X\rangle = X(h_{p+1}) &= \Lie{X}h_{p+1}\\
			&= \Lie{X}\left(\trace \frac1{p+1}N^{p+1}\right)\\
			&= \frac{\cancel{p+1}}{\cancel{p+1}} \trace (N^p \Lie{X}N)\\
			&= \trace (N^{p-1}\Lie{NX}N) \comment{by using~\eqref{eq:nijenhuis_prop}}\\
			&= \Lie{NX}(\trace \frac1p N^p)\\
			&= \langle dh_p, NX \rangle\\
			&= \langle N^* dh_p, X \rangle, \quad \forall X \in \fields(M).
	\end{eqalign}
\end{proof}

Hence with this theorem we found the hierarchy of symmetries we were looking for in the symplectic (non-degenerate) case of a bihamiltonian structure. In fact, if $(\Pi_0,\Pi_1)$ is a compatible pair of Poisson tensors where $\Pi_0$ is non-degenerate, $N=\Pi_0\Pi_0^{-1}$ is Nijenhuis and the hierarchy is given by the spectrum of $N$ (as per previous theorem).

\end{document}